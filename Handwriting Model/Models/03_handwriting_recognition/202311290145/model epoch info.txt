Model: "model_22"
______________________________________________________________________________________________________________
 Layer (type)                       Output Shape            Param #      Connected to                         
==============================================================================================================
 input (InputLayer)                 [(None, 32, 128, 3)]    0            []                                   
                                                                                                              
 lambda_22 (Lambda)                 (None, 32, 128, 3)      0            ['input[0][0]']                      
                                                                                                              
 conv2d_506 (Conv2D)                (None, 32, 128, 16)     448          ['lambda_22[0][0]']                  
                                                                                                              
 batch_normalization_396 (BatchNorm  (None, 32, 128, 16)    64           ['conv2d_506[0][0]']                 
 alization)                                                                                                   
                                                                                                              
 leaky_re_lu_396 (LeakyReLU)        (None, 32, 128, 16)     0            ['batch_normalization_396[0][0]']    
                                                                                                              
 conv2d_507 (Conv2D)                (None, 32, 128, 16)     2320         ['leaky_re_lu_396[0][0]']            
                                                                                                              
 batch_normalization_397 (BatchNorm  (None, 32, 128, 16)    64           ['conv2d_507[0][0]']                 
 alization)                                                                                                   
                                                                                                              
 conv2d_508 (Conv2D)                (None, 32, 128, 16)     64           ['lambda_22[0][0]']                  
                                                                                                              
 add_198 (Add)                      (None, 32, 128, 16)     0            ['batch_normalization_397[0][0]',    
                                                                          'conv2d_508[0][0]']                 
                                                                                                              
 leaky_re_lu_397 (LeakyReLU)        (None, 32, 128, 16)     0            ['add_198[0][0]']                    
                                                                                                              
 dropout_220 (Dropout)              (None, 32, 128, 16)     0            ['leaky_re_lu_397[0][0]']            
                                                                                                              
 conv2d_509 (Conv2D)                (None, 16, 64, 16)      2320         ['dropout_220[0][0]']                
                                                                                                              
 batch_normalization_398 (BatchNorm  (None, 16, 64, 16)     64           ['conv2d_509[0][0]']                 
 alization)                                                                                                   
                                                                                                              
 leaky_re_lu_398 (LeakyReLU)        (None, 16, 64, 16)      0            ['batch_normalization_398[0][0]']    
                                                                                                              
 conv2d_510 (Conv2D)                (None, 16, 64, 16)      2320         ['leaky_re_lu_398[0][0]']            
                                                                                                              
 batch_normalization_399 (BatchNorm  (None, 16, 64, 16)     64           ['conv2d_510[0][0]']                 
 alization)                                                                                                   
                                                                                                              
 conv2d_511 (Conv2D)                (None, 16, 64, 16)      272          ['dropout_220[0][0]']                
                                                                                                              
 add_199 (Add)                      (None, 16, 64, 16)      0            ['batch_normalization_399[0][0]',    
                                                                          'conv2d_511[0][0]']                 
                                                                                                              
 leaky_re_lu_399 (LeakyReLU)        (None, 16, 64, 16)      0            ['add_199[0][0]']                    
                                                                                                              
 dropout_221 (Dropout)              (None, 16, 64, 16)      0            ['leaky_re_lu_399[0][0]']            
                                                                                                              
 conv2d_512 (Conv2D)                (None, 16, 64, 16)      2320         ['dropout_221[0][0]']                
                                                                                                              
 batch_normalization_400 (BatchNorm  (None, 16, 64, 16)     64           ['conv2d_512[0][0]']                 
 alization)                                                                                                   
                                                                                                              
 leaky_re_lu_400 (LeakyReLU)        (None, 16, 64, 16)      0            ['batch_normalization_400[0][0]']    
                                                                                                              
 conv2d_513 (Conv2D)                (None, 16, 64, 16)      2320         ['leaky_re_lu_400[0][0]']            
                                                                                                              
 batch_normalization_401 (BatchNorm  (None, 16, 64, 16)     64           ['conv2d_513[0][0]']                 
 alization)                                                                                                   
                                                                                                              
 add_200 (Add)                      (None, 16, 64, 16)      0            ['batch_normalization_401[0][0]',    
                                                                          'dropout_221[0][0]']                
                                                                                                              
 leaky_re_lu_401 (LeakyReLU)        (None, 16, 64, 16)      0            ['add_200[0][0]']                    
                                                                                                              
 dropout_222 (Dropout)              (None, 16, 64, 16)      0            ['leaky_re_lu_401[0][0]']            
                                                                                                              
 conv2d_514 (Conv2D)                (None, 8, 32, 32)       4640         ['dropout_222[0][0]']                
                                                                                                              
 batch_normalization_402 (BatchNorm  (None, 8, 32, 32)      128          ['conv2d_514[0][0]']                 
 alization)                                                                                                   
                                                                                                              
 leaky_re_lu_402 (LeakyReLU)        (None, 8, 32, 32)       0            ['batch_normalization_402[0][0]']    
                                                                                                              
 conv2d_515 (Conv2D)                (None, 8, 32, 32)       9248         ['leaky_re_lu_402[0][0]']            
                                                                                                              
 batch_normalization_403 (BatchNorm  (None, 8, 32, 32)      128          ['conv2d_515[0][0]']                 
 alization)                                                                                                   
                                                                                                              
 conv2d_516 (Conv2D)                (None, 8, 32, 32)       544          ['dropout_222[0][0]']                
                                                                                                              
 add_201 (Add)                      (None, 8, 32, 32)       0            ['batch_normalization_403[0][0]',    
                                                                          'conv2d_516[0][0]']                 
                                                                                                              
 leaky_re_lu_403 (LeakyReLU)        (None, 8, 32, 32)       0            ['add_201[0][0]']                    
                                                                                                              
 dropout_223 (Dropout)              (None, 8, 32, 32)       0            ['leaky_re_lu_403[0][0]']            
                                                                                                              
 conv2d_517 (Conv2D)                (None, 8, 32, 32)       9248         ['dropout_223[0][0]']                
                                                                                                              
 batch_normalization_404 (BatchNorm  (None, 8, 32, 32)      128          ['conv2d_517[0][0]']                 
 alization)                                                                                                   
                                                                                                              
 leaky_re_lu_404 (LeakyReLU)        (None, 8, 32, 32)       0            ['batch_normalization_404[0][0]']    
                                                                                                              
 conv2d_518 (Conv2D)                (None, 8, 32, 32)       9248         ['leaky_re_lu_404[0][0]']            
                                                                                                              
 batch_normalization_405 (BatchNorm  (None, 8, 32, 32)      128          ['conv2d_518[0][0]']                 
 alization)                                                                                                   
                                                                                                              
 add_202 (Add)                      (None, 8, 32, 32)       0            ['batch_normalization_405[0][0]',    
                                                                          'dropout_223[0][0]']                
                                                                                                              
 leaky_re_lu_405 (LeakyReLU)        (None, 8, 32, 32)       0            ['add_202[0][0]']                    
                                                                                                              
 dropout_224 (Dropout)              (None, 8, 32, 32)       0            ['leaky_re_lu_405[0][0]']            
                                                                                                              
 conv2d_519 (Conv2D)                (None, 4, 16, 64)       18496        ['dropout_224[0][0]']                
                                                                                                              
 batch_normalization_406 (BatchNorm  (None, 4, 16, 64)      256          ['conv2d_519[0][0]']                 
 alization)                                                                                                   
                                                                                                              
 leaky_re_lu_406 (LeakyReLU)        (None, 4, 16, 64)       0            ['batch_normalization_406[0][0]']    
                                                                                                              
 conv2d_520 (Conv2D)                (None, 4, 16, 64)       36928        ['leaky_re_lu_406[0][0]']            
                                                                                                              
 batch_normalization_407 (BatchNorm  (None, 4, 16, 64)      256          ['conv2d_520[0][0]']                 
 alization)                                                                                                   
                                                                                                              
 conv2d_521 (Conv2D)                (None, 4, 16, 64)       2112         ['dropout_224[0][0]']                
                                                                                                              
 add_203 (Add)                      (None, 4, 16, 64)       0            ['batch_normalization_407[0][0]',    
                                                                          'conv2d_521[0][0]']                 
                                                                                                              
 leaky_re_lu_407 (LeakyReLU)        (None, 4, 16, 64)       0            ['add_203[0][0]']                    
                                                                                                              
 dropout_225 (Dropout)              (None, 4, 16, 64)       0            ['leaky_re_lu_407[0][0]']            
                                                                                                              
 conv2d_522 (Conv2D)                (None, 4, 16, 64)       36928        ['dropout_225[0][0]']                
                                                                                                              
 batch_normalization_408 (BatchNorm  (None, 4, 16, 64)      256          ['conv2d_522[0][0]']                 
 alization)                                                                                                   
                                                                                                              
 leaky_re_lu_408 (LeakyReLU)        (None, 4, 16, 64)       0            ['batch_normalization_408[0][0]']    
                                                                                                              
 conv2d_523 (Conv2D)                (None, 4, 16, 64)       36928        ['leaky_re_lu_408[0][0]']            
                                                                                                              
 batch_normalization_409 (BatchNorm  (None, 4, 16, 64)      256          ['conv2d_523[0][0]']                 
 alization)                                                                                                   
                                                                                                              
 conv2d_524 (Conv2D)                (None, 4, 16, 64)       4160         ['dropout_225[0][0]']                
                                                                                                              
 add_204 (Add)                      (None, 4, 16, 64)       0            ['batch_normalization_409[0][0]',    
                                                                          'conv2d_524[0][0]']                 
                                                                                                              
 leaky_re_lu_409 (LeakyReLU)        (None, 4, 16, 64)       0            ['add_204[0][0]']                    
                                                                                                              
 dropout_226 (Dropout)              (None, 4, 16, 64)       0            ['leaky_re_lu_409[0][0]']            
                                                                                                              
 conv2d_525 (Conv2D)                (None, 4, 16, 64)       36928        ['dropout_226[0][0]']                
                                                                                                              
 batch_normalization_410 (BatchNorm  (None, 4, 16, 64)      256          ['conv2d_525[0][0]']                 
 alization)                                                                                                   
                                                                                                              
 leaky_re_lu_410 (LeakyReLU)        (None, 4, 16, 64)       0            ['batch_normalization_410[0][0]']    
                                                                                                              
 conv2d_526 (Conv2D)                (None, 4, 16, 64)       36928        ['leaky_re_lu_410[0][0]']            
                                                                                                              
 batch_normalization_411 (BatchNorm  (None, 4, 16, 64)      256          ['conv2d_526[0][0]']                 
 alization)                                                                                                   
                                                                                                              
 add_205 (Add)                      (None, 4, 16, 64)       0            ['batch_normalization_411[0][0]',    
                                                                          'dropout_226[0][0]']                
                                                                                                              
 leaky_re_lu_411 (LeakyReLU)        (None, 4, 16, 64)       0            ['add_205[0][0]']                    
                                                                                                              
 dropout_227 (Dropout)              (None, 4, 16, 64)       0            ['leaky_re_lu_411[0][0]']            
                                                                                                              
 conv2d_527 (Conv2D)                (None, 4, 16, 64)       36928        ['dropout_227[0][0]']                
                                                                                                              
 batch_normalization_412 (BatchNorm  (None, 4, 16, 64)      256          ['conv2d_527[0][0]']                 
 alization)                                                                                                   
                                                                                                              
 leaky_re_lu_412 (LeakyReLU)        (None, 4, 16, 64)       0            ['batch_normalization_412[0][0]']    
                                                                                                              
 conv2d_528 (Conv2D)                (None, 4, 16, 64)       36928        ['leaky_re_lu_412[0][0]']            
                                                                                                              
 batch_normalization_413 (BatchNorm  (None, 4, 16, 64)      256          ['conv2d_528[0][0]']                 
 alization)                                                                                                   
                                                                                                              
 add_206 (Add)                      (None, 4, 16, 64)       0            ['batch_normalization_413[0][0]',    
                                                                          'dropout_227[0][0]']                
                                                                                                              
 leaky_re_lu_413 (LeakyReLU)        (None, 4, 16, 64)       0            ['add_206[0][0]']                    
                                                                                                              
 dropout_228 (Dropout)              (None, 4, 16, 64)       0            ['leaky_re_lu_413[0][0]']            
                                                                                                              
 reshape_22 (Reshape)               (None, 64, 64)          0            ['dropout_228[0][0]']                
                                                                                                              
 bidirectional_22 (Bidirectional)   (None, 64, 256)         197632       ['reshape_22[0][0]']                 
                                                                                                              
 dropout_229 (Dropout)              (None, 64, 256)         0            ['bidirectional_22[0][0]']           
                                                                                                              
 output (Dense)                     (None, 64, 79)          20303        ['dropout_229[0][0]']                
                                                                                                              
==============================================================================================================
Total params: 549,455
Trainable params: 547,983
Non-trainable params: 1,472
______________________________________________________________________________________________________________
Epoch 1/50
5425/5426 [============================>.] - ETA: 0s - loss: 12.8330 - CER: 1.0937 - WER: 0.9645
Epoch 1: val_CER improved from inf to 0.61856, saving model to Models/03_handwriting_recognition/202311290145/model.h5
5426/5426 [==============================] - 245s 44ms/step - loss: 12.8321 - CER: 1.0936 - WER: 0.9644 - val_loss: 10.2289 - val_CER: 0.6186 - val_WER: 0.8152 - lr: 5.0000e-04
Epoch 2/50
5425/5426 [============================>.] - ETA: 0s - loss: 9.0489 - CER: 0.5921 - WER: 0.7954
Epoch 2: val_CER improved from 0.61856 to 0.43096, saving model to Models/03_handwriting_recognition/202311290145/model.h5
5426/5426 [==============================] - 227s 42ms/step - loss: 9.0480 - CER: 0.5921 - WER: 0.7953 - val_loss: 7.0237 - val_CER: 0.4310 - val_WER: 0.6898 - lr: 5.0000e-04
Epoch 3/50
5426/5426 [==============================] - ETA: 0s - loss: 7.1654 - CER: 0.4606 - WER: 0.7119
Epoch 3: val_CER improved from 0.43096 to 0.31001, saving model to Models/03_handwriting_recognition/202311290145/model.h5
5426/5426 [==============================] - 226s 42ms/step - loss: 7.1654 - CER: 0.4606 - WER: 0.7119 - val_loss: 5.2034 - val_CER: 0.3100 - val_WER: 0.5997 - lr: 5.0000e-04
Epoch 4/50
5425/5426 [============================>.] - ETA: 0s - loss: 5.8713 - CER: 0.3646 - WER: 0.6456
Epoch 4: val_CER improved from 0.31001 to 0.23292, saving model to Models/03_handwriting_recognition/202311290145/model.h5
5426/5426 [==============================] - 228s 42ms/step - loss: 5.8713 - CER: 0.3646 - WER: 0.6456 - val_loss: 3.9849 - val_CER: 0.2329 - val_WER: 0.5104 - lr: 5.0000e-04
Epoch 5/50
5425/5426 [============================>.] - ETA: 0s - loss: 5.0502 - CER: 0.3072 - WER: 0.5914
Epoch 5: val_CER improved from 0.23292 to 0.20703, saving model to Models/03_handwriting_recognition/202311290145/model.h5
5426/5426 [==============================] - 234s 43ms/step - loss: 5.0502 - CER: 0.3072 - WER: 0.5914 - val_loss: 3.5033 - val_CER: 0.2070 - val_WER: 0.4746 - lr: 5.0000e-04
Epoch 6/50
5426/5426 [==============================] - ETA: 0s - loss: 4.5469 - CER: 0.2737 - WER: 0.5603
Epoch 6: val_CER did not improve from 0.20703
5426/5426 [==============================] - 235s 43ms/step - loss: 4.5469 - CER: 0.2736 - WER: 0.5603 - val_loss: 3.7758 - val_CER: 0.2231 - val_WER: 0.4935 - lr: 5.0000e-04
Epoch 7/50
5426/5426 [==============================] - ETA: 0s - loss: 4.2185 - CER: 0.2551 - WER: 0.5360
Epoch 7: val_CER did not improve from 0.20703
5426/5426 [==============================] - 232s 43ms/step - loss: 4.2185 - CER: 0.2551 - WER: 0.5360 - val_loss: 8.2555 - val_CER: 0.4856 - val_WER: 0.7615 - lr: 5.0000e-04
Epoch 8/50
5426/5426 [==============================] - ETA: 0s - loss: 3.9457 - CER: 0.2351 - WER: 0.5061
Epoch 8: val_CER improved from 0.20703 to 0.16974, saving model to Models/03_handwriting_recognition/202311290145/model.h5
5426/5426 [==============================] - 231s 42ms/step - loss: 3.9457 - CER: 0.2351 - WER: 0.5061 - val_loss: 2.7887 - val_CER: 0.1697 - val_WER: 0.4078 - lr: 5.0000e-04
Epoch 9/50
5426/5426 [==============================] - ETA: 0s - loss: 3.7435 - CER: 0.2238 - WER: 0.4901
Epoch 9: val_CER did not improve from 0.16974
5426/5426 [==============================] - 232s 43ms/step - loss: 3.7435 - CER: 0.2238 - WER: 0.4901 - val_loss: 2.8187 - val_CER: 0.1759 - val_WER: 0.4130 - lr: 5.0000e-04
Epoch 10/50
5425/5426 [============================>.] - ETA: 0s - loss: 3.7281 - CER: 0.2178 - WER: 0.4821
Epoch 10: val_CER improved from 0.16974 to 0.14649, saving model to Models/03_handwriting_recognition/202311290145/model.h5
5426/5426 [==============================] - 232s 43ms/step - loss: 3.7282 - CER: 0.2178 - WER: 0.4821 - val_loss: 2.5139 - val_CER: 0.1465 - val_WER: 0.3677 - lr: 5.0000e-04
Epoch 11/50
5425/5426 [============================>.] - ETA: 0s - loss: 3.5211 - CER: 0.2139 - WER: 0.4771
Epoch 11: val_CER did not improve from 0.14649
5426/5426 [==============================] - 231s 43ms/step - loss: 3.5212 - CER: 0.2139 - WER: 0.4771 - val_loss: 2.4296 - val_CER: 0.1505 - val_WER: 0.3683 - lr: 5.0000e-04
Epoch 12/50
5425/5426 [============================>.] - ETA: 0s - loss: 3.3152 - CER: 0.2006 - WER: 0.4533
Epoch 12: val_CER did not improve from 0.14649
5426/5426 [==============================] - 231s 43ms/step - loss: 3.3150 - CER: 0.2006 - WER: 0.4533 - val_loss: 2.3870 - val_CER: 0.1478 - val_WER: 0.3601 - lr: 5.0000e-04
Epoch 13/50
5425/5426 [============================>.] - ETA: 0s - loss: 3.1714 - CER: 0.1911 - WER: 0.4374
Epoch 13: val_CER did not improve from 0.14649
5426/5426 [==============================] - 231s 43ms/step - loss: 3.1712 - CER: 0.1911 - WER: 0.4374 - val_loss: 3.8175 - val_CER: 0.2239 - val_WER: 0.4763 - lr: 5.0000e-04
Epoch 14/50
5426/5426 [==============================] - ETA: 0s - loss: 3.0456 - CER: 0.1865 - WER: 0.4304
Epoch 14: val_CER improved from 0.14649 to 0.12861, saving model to Models/03_handwriting_recognition/202311290145/model.h5
5426/5426 [==============================] - 231s 43ms/step - loss: 3.0456 - CER: 0.1865 - WER: 0.4304 - val_loss: 2.1343 - val_CER: 0.1286 - val_WER: 0.3309 - lr: 5.0000e-04
Epoch 15/50
5426/5426 [==============================] - ETA: 0s - loss: 2.9651 - CER: 0.1779 - WER: 0.4185
Epoch 15: val_CER improved from 0.12861 to 0.12029, saving model to Models/03_handwriting_recognition/202311290145/model.h5
5426/5426 [==============================] - 232s 43ms/step - loss: 2.9651 - CER: 0.1779 - WER: 0.4185 - val_loss: 2.0636 - val_CER: 0.1203 - val_WER: 0.3140 - lr: 5.0000e-04
Epoch 16/50
5425/5426 [============================>.] - ETA: 0s - loss: 2.8613 - CER: 0.1756 - WER: 0.4106
Epoch 16: val_CER improved from 0.12029 to 0.11714, saving model to Models/03_handwriting_recognition/202311290145/model.h5
5426/5426 [==============================] - 232s 43ms/step - loss: 2.8614 - CER: 0.1756 - WER: 0.4106 - val_loss: 1.9710 - val_CER: 0.1171 - val_WER: 0.3091 - lr: 5.0000e-04
Epoch 17/50
5425/5426 [============================>.] - ETA: 0s - loss: 2.7924 - CER: 0.1695 - WER: 0.4037
Epoch 17: val_CER did not improve from 0.11714
5426/5426 [==============================] - 228s 42ms/step - loss: 2.7922 - CER: 0.1695 - WER: 0.4037 - val_loss: 1.9689 - val_CER: 0.1177 - val_WER: 0.2997 - lr: 5.0000e-04
Epoch 18/50
5426/5426 [==============================] - ETA: 0s - loss: 2.7034 - CER: 0.1636 - WER: 0.3937
Epoch 18: val_CER improved from 0.11714 to 0.11584, saving model to Models/03_handwriting_recognition/202311290145/model.h5
5426/5426 [==============================] - 225s 42ms/step - loss: 2.7034 - CER: 0.1636 - WER: 0.3937 - val_loss: 1.9282 - val_CER: 0.1158 - val_WER: 0.3004 - lr: 5.0000e-04
Epoch 19/50
5426/5426 [==============================] - ETA: 0s - loss: 2.6538 - CER: 0.1612 - WER: 0.3876
Epoch 19: val_CER improved from 0.11584 to 0.11013, saving model to Models/03_handwriting_recognition/202311290145/model.h5
5426/5426 [==============================] - 225s 41ms/step - loss: 2.6538 - CER: 0.1612 - WER: 0.3876 - val_loss: 1.7837 - val_CER: 0.1101 - val_WER: 0.2845 - lr: 5.0000e-04
Epoch 20/50
5426/5426 [==============================] - ETA: 0s - loss: 2.6020 - CER: 0.1579 - WER: 0.3827
Epoch 20: val_CER did not improve from 0.11013
5426/5426 [==============================] - 227s 42ms/step - loss: 2.6020 - CER: 0.1579 - WER: 0.3827 - val_loss: 1.8935 - val_CER: 0.1115 - val_WER: 0.2937 - lr: 5.0000e-04
Epoch 21/50
5426/5426 [==============================] - ETA: 0s - loss: 2.5451 - CER: 0.1544 - WER: 0.3766
Epoch 21: val_CER improved from 0.11013 to 0.10776, saving model to Models/03_handwriting_recognition/202311290145/model.h5
5426/5426 [==============================] - 232s 43ms/step - loss: 2.5451 - CER: 0.1544 - WER: 0.3766 - val_loss: 1.8601 - val_CER: 0.1078 - val_WER: 0.2828 - lr: 5.0000e-04
Epoch 22/50
5425/5426 [============================>.] - ETA: 0s - loss: 2.4939 - CER: 0.1504 - WER: 0.3697
Epoch 22: val_CER did not improve from 0.10776
5426/5426 [==============================] - 232s 43ms/step - loss: 2.4938 - CER: 0.1504 - WER: 0.3697 - val_loss: 1.8204 - val_CER: 0.1082 - val_WER: 0.2880 - lr: 5.0000e-04
Epoch 23/50
5425/5426 [============================>.] - ETA: 0s - loss: 2.4588 - CER: 0.1500 - WER: 0.3681
Epoch 23: val_CER improved from 0.10776 to 0.10610, saving model to Models/03_handwriting_recognition/202311290145/model.h5
5426/5426 [==============================] - 230s 42ms/step - loss: 2.4588 - CER: 0.1500 - WER: 0.3681 - val_loss: 1.8379 - val_CER: 0.1061 - val_WER: 0.2806 - lr: 5.0000e-04
Epoch 24/50
5425/5426 [============================>.] - ETA: 0s - loss: 2.4264 - CER: 0.1481 - WER: 0.3667
Epoch 24: val_CER did not improve from 0.10610
5426/5426 [==============================] - 232s 43ms/step - loss: 2.4262 - CER: 0.1481 - WER: 0.3667 - val_loss: 2.1367 - val_CER: 0.1338 - val_WER: 0.3223 - lr: 5.0000e-04
Epoch 25/50
5426/5426 [==============================] - ETA: 0s - loss: 2.3888 - CER: 0.1456 - WER: 0.3595
Epoch 25: val_CER did not improve from 0.10610
5426/5426 [==============================] - 230s 42ms/step - loss: 2.3888 - CER: 0.1456 - WER: 0.3595 - val_loss: 1.7808 - val_CER: 0.1086 - val_WER: 0.2822 - lr: 5.0000e-04
Epoch 26/50
5425/5426 [============================>.] - ETA: 0s - loss: 2.3181 - CER: 0.1402 - WER: 0.3517
Epoch 27: val_CER improved from 0.10281 to 0.09925, saving model to Models/03_handwriting_recognition/202311290145/model.h5
5426/5426 [==============================] - 231s 42ms/step - loss: 2.3182 - CER: 0.1402 - WER: 0.3517 - val_loss: 1.6492 - val_CER: 0.0992 - val_WER: 0.2630 - lr: 5.0000e-04
Epoch 28/50
5426/5426 [==============================] - ETA: 0s - loss: 2.2694 - CER: 0.1393 - WER: 0.3475
Epoch 28: val_CER improved from 0.09925 to 0.09410, saving model to Models/03_handwriting_recognition/202311290145/model.h5
5426/5426 [==============================] - 230s 42ms/step - loss: 2.2694 - CER: 0.1393 - WER: 0.3475 - val_loss: 1.5520 - val_CER: 0.0941 - val_WER: 0.2518 - lr: 5.0000e-04
Epoch 29/50
5425/5426 [============================>.] - ETA: 0s - loss: 2.2578 - CER: 0.1392 - WER: 0.3456
Epoch 29: val_CER did not improve from 0.09410
5426/5426 [==============================] - 230s 42ms/step - loss: 2.2578 - CER: 0.1392 - WER: 0.3456 - val_loss: 1.6272 - val_CER: 0.0984 - val_WER: 0.2602 - lr: 5.0000e-04
Epoch 30/50
5425/5426 [============================>.] - ETA: 0s - loss: 2.2233 - CER: 0.1341 - WER: 0.3381
Epoch 30: val_CER improved from 0.09410 to 0.09216, saving model to Models/03_handwriting_recognition/202311290145/model.h5
5426/5426 [==============================] - 230s 42ms/step - loss: 2.2232 - CER: 0.1341 - WER: 0.3381 - val_loss: 1.5480 - val_CER: 0.0922 - val_WER: 0.2501 - lr: 5.0000e-04
Epoch 31/50
5425/5426 [============================>.] - ETA: 0s - loss: 2.2003 - CER: 0.1349 - WER: 0.3396
Epoch 31: val_CER did not improve from 0.09216
5426/5426 [==============================] - 230s 42ms/step - loss: 2.2003 - CER: 0.1349 - WER: 0.3396 - val_loss: 1.5317 - val_CER: 0.0934 - val_WER: 0.2493 - lr: 5.0000e-04
Epoch 32/50
5426/5426 [==============================] - ETA: 0s - loss: 2.1700 - CER: 0.1333 - WER: 0.3361
Epoch 32: val_CER did not improve from 0.09216
5426/5426 [==============================] - 230s 42ms/step - loss: 2.1700 - CER: 0.1333 - WER: 0.3361 - val_loss: 1.5345 - val_CER: 0.0924 - val_WER: 0.2469 - lr: 5.0000e-04
Epoch 33/50
5425/5426 [============================>.] - ETA: 0s - loss: 2.1569 - CER: 0.1331 - WER: 0.3351
Epoch 33: val_CER improved from 0.09216 to 0.09049, saving model to Models/03_handwriting_recognition/202311290145/model.h5
5426/5426 [==============================] - 226s 42ms/step - loss: 2.1568 - CER: 0.1331 - WER: 0.3351 - val_loss: 1.5144 - val_CER: 0.0905 - val_WER: 0.2459 - lr: 5.0000e-04
Epoch 34/50
5425/5426 [============================>.] - ETA: 0s - loss: 2.1269 - CER: 0.1296 - WER: 0.3278
Epoch 34: val_CER improved from 0.09049 to 0.08862, saving model to Models/03_handwriting_recognition/202311290145/model.h5
5426/5426 [==============================] - 226s 42ms/step - loss: 2.1284 - CER: 0.1296 - WER: 0.3279 - val_loss: 1.5169 - val_CER: 0.0886 - val_WER: 0.2426 - lr: 5.0000e-04
Epoch 35/50
5425/5426 [============================>.] - ETA: 0s - loss: 2.1038 - CER: 0.1281 - WER: 0.3262
Epoch 35: val_CER did not improve from 0.08862
5426/5426 [==============================] - 225s 41ms/step - loss: 2.1043 - CER: 0.1281 - WER: 0.3262 - val_loss: 1.7930 - val_CER: 0.1020 - val_WER: 0.2706 - lr: 5.0000e-04
Epoch 36/50
5426/5426 [==============================] - ETA: 0s - loss: 2.0852 - CER: 0.1278 - WER: 0.3256
Epoch 36: val_CER did not improve from 0.08862
5426/5426 [==============================] - 227s 42ms/step - loss: 2.0852 - CER: 0.1278 - WER: 0.3256 - val_loss: 1.5172 - val_CER: 0.0900 - val_WER: 0.2463 - lr: 5.0000e-04
Epoch 37/50
5425/5426 [============================>.] - ETA: 0s - loss: 2.0639 - CER: 0.1284 - WER: 0.3251
Epoch 37: val_CER did not improve from 0.08862
5426/5426 [==============================] - 230s 42ms/step - loss: 2.0637 - CER: 0.1284 - WER: 0.3251 - val_loss: 1.5688 - val_CER: 0.0953 - val_WER: 0.2521 - lr: 5.0000e-04
Epoch 38/50
5426/5426 [==============================] - ETA: 0s - loss: 2.0454 - CER: 0.1257 - WER: 0.3227
Epoch 38: val_CER did not improve from 0.08862
5426/5426 [==============================] - 229s 42ms/step - loss: 2.0454 - CER: 0.1257 - WER: 0.3227 - val_loss: 1.4890 - val_CER: 0.0893 - val_WER: 0.2379 - lr: 5.0000e-04
Epoch 39/50
5425/5426 [============================>.] - ETA: 0s - loss: 2.0326 - CER: 0.1268 - WER: 0.3251
Epoch 39: val_CER did not improve from 0.08862
5426/5426 [==============================] - 231s 42ms/step - loss: 2.0324 - CER: 0.1268 - WER: 0.3251 - val_loss: 1.5374 - val_CER: 0.0940 - val_WER: 0.2509 - lr: 5.0000e-04
Epoch 40/50
5426/5426 [==============================] - ETA: 0s - loss: 2.0075 - CER: 0.1231 - WER: 0.3166
Epoch 40: val_CER improved from 0.08862 to 0.08843, saving model to Models/03_handwriting_recognition/202311290145/model.h5
5426/5426 [==============================] - 233s 43ms/step - loss: 2.0075 - CER: 0.1231 - WER: 0.3166 - val_loss: 1.4758 - val_CER: 0.0884 - val_WER: 0.2394 - lr: 5.0000e-04
Epoch 41/50
5426/5426 [==============================] - ETA: 0s - loss: 1.9969 - CER: 0.1233 - WER: 0.3133
Epoch 41: val_CER did not improve from 0.08843
5426/5426 [==============================] - 233s 43ms/step - loss: 1.9969 - CER: 0.1233 - WER: 0.3133 - val_loss: 1.5124 - val_CER: 0.0895 - val_WER: 0.2395 - lr: 5.0000e-04
Epoch 42/50
5425/5426 [============================>.] - ETA: 0s - loss: 1.9800 - CER: 0.1233 - WER: 0.3175
Epoch 42: val_CER did not improve from 0.08843
5426/5426 [==============================] - 233s 43ms/step - loss: 1.9801 - CER: 0.1233 - WER: 0.3175 - val_loss: 1.4605 - val_CER: 0.0896 - val_WER: 0.2348 - lr: 5.0000e-04
Epoch 43/50
5426/5426 [==============================] - ETA: 0s - loss: 1.9564 - CER: 0.1205 - WER: 0.3104
Epoch 43: val_CER did not improve from 0.08843
5426/5426 [==============================] - 234s 43ms/step - loss: 1.9564 - CER: 0.1205 - WER: 0.3104 - val_loss: 1.5267 - val_CER: 0.0937 - val_WER: 0.2438 - lr: 5.0000e-04
Epoch 44/50
5425/5426 [============================>.] - ETA: 0s - loss: 1.9489 - CER: 0.1189 - WER: 0.3064
Epoch 44: val_CER improved from 0.08843 to 0.08458, saving model to Models/03_handwriting_recognition/202311290145/model.h5
5426/5426 [==============================] - 233s 43ms/step - loss: 1.9491 - CER: 0.1189 - WER: 0.3064 - val_loss: 1.4104 - val_CER: 0.0846 - val_WER: 0.2299 - lr: 5.0000e-04
Epoch 45/50
5425/5426 [============================>.] - ETA: 0s - loss: 1.9314 - CER: 0.1194 - WER: 0.3114
Epoch 45: val_CER did not improve from 0.08458
5426/5426 [==============================] - 231s 43ms/step - loss: 1.9312 - CER: 0.1194 - WER: 0.3114 - val_loss: 1.4209 - val_CER: 0.0871 - val_WER: 0.2301 - lr: 5.0000e-04
Epoch 46/50
5425/5426 [============================>.] - ETA: 0s - loss: 1.9174 - CER: 0.1181 - WER: 0.3040
Epoch 46: val_CER did not improve from 0.08458
5426/5426 [==============================] - 231s 43ms/step - loss: 1.9173 - CER: 0.1181 - WER: 0.3041 - val_loss: 1.5422 - val_CER: 0.0913 - val_WER: 0.2451 - lr: 5.0000e-04
Epoch 47/50
5425/5426 [============================>.] - ETA: 0s - loss: 1.8973 - CER: 0.1168 - WER: 0.3030
Epoch 47: val_CER did not improve from 0.08458
5426/5426 [==============================] - 230s 42ms/step - loss: 1.8971 - CER: 0.1168 - WER: 0.3030 - val_loss: 1.7427 - val_CER: 0.1131 - val_WER: 0.2783 - lr: 5.0000e-04
Epoch 48/50
5425/5426 [============================>.] - ETA: 0s - loss: 1.8964 - CER: 0.1167 - WER: 0.3041
Epoch 48: val_CER improved from 0.08458 to 0.08161, saving model to Models/03_handwriting_recognition/202311290145/model.h5
5426/5426 [==============================] - 231s 42ms/step - loss: 1.8965 - CER: 0.1167 - WER: 0.3041 - val_loss: 1.3866 - val_CER: 0.0816 - val_WER: 0.2249 - lr: 5.0000e-04
Epoch 49/50
5426/5426 [==============================] - ETA: 0s - loss: 1.8684 - CER: 0.1158 - WER: 0.3039
Epoch 49: val_CER improved from 0.08161 to 0.08116, saving model to Models/03_handwriting_recognition/202311290145/model.h5
5426/5426 [==============================] - 227s 42ms/step - loss: 1.8684 - CER: 0.1158 - WER: 0.3039 - val_loss: 1.3974 - val_CER: 0.0812 - val_WER: 0.2242 - lr: 5.0000e-04
Epoch 50/50
5425/5426 [============================>.] - ETA: 0s - loss: 1.8520 - CER: 0.1150 - WER: 0.3007
Epoch 50: val_CER did not improve from 0.08116
5426/5426 [==============================] - 225s 41ms/step - loss: 1.8519 - CER: 0.1150 - WER: 0.3007 - val_loss: 1.3799 - val_CER: 0.0827 - val_WER: 0.2210 - lr: 5.0000e-04