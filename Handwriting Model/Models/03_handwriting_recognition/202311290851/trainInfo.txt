Model: "model"
______________________________________________________________________________________________________________
 Layer (type)                       Output Shape            Param #      Connected to                         
==============================================================================================================
 input (InputLayer)                 [(None, 32, 128, 3)]    0            []                                   
                                                                                                              
 lambda (Lambda)                    (None, 32, 128, 3)      0            ['input[0][0]']                      
                                                                                                              
 conv2d (Conv2D)                    (None, 32, 128, 16)     448          ['lambda[0][0]']                     
                                                                                                              
 batch_normalization (BatchNormaliz  (None, 32, 128, 16)    64           ['conv2d[0][0]']                     
 ation)                                                                                                       
                                                                                                              
 leaky_re_lu (LeakyReLU)            (None, 32, 128, 16)     0            ['batch_normalization[0][0]']        
                                                                                                              
 conv2d_1 (Conv2D)                  (None, 32, 128, 16)     2320         ['leaky_re_lu[0][0]']                
                                                                                                              
 batch_normalization_1 (BatchNormal  (None, 32, 128, 16)    64           ['conv2d_1[0][0]']                   
 ization)                                                                                                     
                                                                                                              
 conv2d_2 (Conv2D)                  (None, 32, 128, 16)     64           ['lambda[0][0]']                     
                                                                                                              
 add (Add)                          (None, 32, 128, 16)     0            ['batch_normalization_1[0][0]',      
                                                                          'conv2d_2[0][0]']                   
                                                                                                              
 leaky_re_lu_1 (LeakyReLU)          (None, 32, 128, 16)     0            ['add[0][0]']                        
                                                                                                              
 dropout (Dropout)                  (None, 32, 128, 16)     0            ['leaky_re_lu_1[0][0]']              
                                                                                                              
 conv2d_3 (Conv2D)                  (None, 16, 64, 16)      2320         ['dropout[0][0]']                    
                                                                                                              
 batch_normalization_2 (BatchNormal  (None, 16, 64, 16)     64           ['conv2d_3[0][0]']                   
 ization)                                                                                                     
                                                                                                              
 leaky_re_lu_2 (LeakyReLU)          (None, 16, 64, 16)      0            ['batch_normalization_2[0][0]']      
                                                                                                              
 conv2d_4 (Conv2D)                  (None, 16, 64, 16)      2320         ['leaky_re_lu_2[0][0]']              
                                                                                                              
 batch_normalization_3 (BatchNormal  (None, 16, 64, 16)     64           ['conv2d_4[0][0]']                   
 ization)                                                                                                     
                                                                                                              
 conv2d_5 (Conv2D)                  (None, 16, 64, 16)      272          ['dropout[0][0]']                    
                                                                                                              
 add_1 (Add)                        (None, 16, 64, 16)      0            ['batch_normalization_3[0][0]',      
                                                                          'conv2d_5[0][0]']                   
                                                                                                              
 leaky_re_lu_3 (LeakyReLU)          (None, 16, 64, 16)      0            ['add_1[0][0]']                      
                                                                                                              
 dropout_1 (Dropout)                (None, 16, 64, 16)      0            ['leaky_re_lu_3[0][0]']              
                                                                                                              
 conv2d_6 (Conv2D)                  (None, 16, 64, 16)      2320         ['dropout_1[0][0]']                  
                                                                                                              
 batch_normalization_4 (BatchNormal  (None, 16, 64, 16)     64           ['conv2d_6[0][0]']                   
 ization)                                                                                                     
                                                                                                              
 leaky_re_lu_4 (LeakyReLU)          (None, 16, 64, 16)      0            ['batch_normalization_4[0][0]']      
                                                                                                              
 conv2d_7 (Conv2D)                  (None, 16, 64, 16)      2320         ['leaky_re_lu_4[0][0]']              
                                                                                                              
 batch_normalization_5 (BatchNormal  (None, 16, 64, 16)     64           ['conv2d_7[0][0]']                   
 ization)                                                                                                     
                                                                                                              
 add_2 (Add)                        (None, 16, 64, 16)      0            ['batch_normalization_5[0][0]',      
                                                                          'dropout_1[0][0]']                  
                                                                                                              
 leaky_re_lu_5 (LeakyReLU)          (None, 16, 64, 16)      0            ['add_2[0][0]']                      
                                                                                                              
 dropout_2 (Dropout)                (None, 16, 64, 16)      0            ['leaky_re_lu_5[0][0]']              
                                                                                                              
 conv2d_8 (Conv2D)                  (None, 8, 32, 32)       4640         ['dropout_2[0][0]']                  
                                                                                                              
 batch_normalization_6 (BatchNormal  (None, 8, 32, 32)      128          ['conv2d_8[0][0]']                   
 ization)                                                                                                     
                                                                                                              
 leaky_re_lu_6 (LeakyReLU)          (None, 8, 32, 32)       0            ['batch_normalization_6[0][0]']      
                                                                                                              
 conv2d_9 (Conv2D)                  (None, 8, 32, 32)       9248         ['leaky_re_lu_6[0][0]']              
                                                                                                              
 batch_normalization_7 (BatchNormal  (None, 8, 32, 32)      128          ['conv2d_9[0][0]']                   
 ization)                                                                                                     
                                                                                                              
 conv2d_10 (Conv2D)                 (None, 8, 32, 32)       544          ['dropout_2[0][0]']                  
                                                                                                              
 add_3 (Add)                        (None, 8, 32, 32)       0            ['batch_normalization_7[0][0]',      
                                                                          'conv2d_10[0][0]']                  
                                                                                                              
 leaky_re_lu_7 (LeakyReLU)          (None, 8, 32, 32)       0            ['add_3[0][0]']                      
                                                                                                              
 dropout_3 (Dropout)                (None, 8, 32, 32)       0            ['leaky_re_lu_7[0][0]']              
                                                                                                              
 conv2d_11 (Conv2D)                 (None, 8, 32, 32)       9248         ['dropout_3[0][0]']                  
                                                                                                              
 batch_normalization_8 (BatchNormal  (None, 8, 32, 32)      128          ['conv2d_11[0][0]']                  
 ization)                                                                                                     
                                                                                                              
 leaky_re_lu_8 (LeakyReLU)          (None, 8, 32, 32)       0            ['batch_normalization_8[0][0]']      
                                                                                                              
 conv2d_12 (Conv2D)                 (None, 8, 32, 32)       9248         ['leaky_re_lu_8[0][0]']              
                                                                                                              
 batch_normalization_9 (BatchNormal  (None, 8, 32, 32)      128          ['conv2d_12[0][0]']                  
 ization)                                                                                                     
                                                                                                              
 add_4 (Add)                        (None, 8, 32, 32)       0            ['batch_normalization_9[0][0]',      
                                                                          'dropout_3[0][0]']                  
                                                                                                              
 leaky_re_lu_9 (LeakyReLU)          (None, 8, 32, 32)       0            ['add_4[0][0]']                      
                                                                                                              
 dropout_4 (Dropout)                (None, 8, 32, 32)       0            ['leaky_re_lu_9[0][0]']              
                                                                                                              
 conv2d_13 (Conv2D)                 (None, 4, 16, 64)       18496        ['dropout_4[0][0]']                  
                                                                                                              
 batch_normalization_10 (BatchNorma  (None, 4, 16, 64)      256          ['conv2d_13[0][0]']                  
 lization)                                                                                                    
                                                                                                              
 leaky_re_lu_10 (LeakyReLU)         (None, 4, 16, 64)       0            ['batch_normalization_10[0][0]']     
                                                                                                              
 conv2d_14 (Conv2D)                 (None, 4, 16, 64)       36928        ['leaky_re_lu_10[0][0]']             
                                                                                                              
 batch_normalization_11 (BatchNorma  (None, 4, 16, 64)      256          ['conv2d_14[0][0]']                  
 lization)                                                                                                    
                                                                                                              
 conv2d_15 (Conv2D)                 (None, 4, 16, 64)       2112         ['dropout_4[0][0]']                  
                                                                                                              
 add_5 (Add)                        (None, 4, 16, 64)       0            ['batch_normalization_11[0][0]',     
                                                                          'conv2d_15[0][0]']                  
                                                                                                              
 leaky_re_lu_11 (LeakyReLU)         (None, 4, 16, 64)       0            ['add_5[0][0]']                      
                                                                                                              
 dropout_5 (Dropout)                (None, 4, 16, 64)       0            ['leaky_re_lu_11[0][0]']             
                                                                                                              
 conv2d_16 (Conv2D)                 (None, 4, 16, 64)       36928        ['dropout_5[0][0]']                  
                                                                                                              
 batch_normalization_12 (BatchNorma  (None, 4, 16, 64)      256          ['conv2d_16[0][0]']                  
 lization)                                                                                                    
                                                                                                              
 leaky_re_lu_12 (LeakyReLU)         (None, 4, 16, 64)       0            ['batch_normalization_12[0][0]']     
                                                                                                              
 conv2d_17 (Conv2D)                 (None, 4, 16, 64)       36928        ['leaky_re_lu_12[0][0]']             
                                                                                                              
 batch_normalization_13 (BatchNorma  (None, 4, 16, 64)      256          ['conv2d_17[0][0]']                  
 lization)                                                                                                    
                                                                                                              
 conv2d_18 (Conv2D)                 (None, 4, 16, 64)       4160         ['dropout_5[0][0]']                  
                                                                                                              
 add_6 (Add)                        (None, 4, 16, 64)       0            ['batch_normalization_13[0][0]',     
                                                                          'conv2d_18[0][0]']                  
                                                                                                              
 leaky_re_lu_13 (LeakyReLU)         (None, 4, 16, 64)       0            ['add_6[0][0]']                      
                                                                                                              
 dropout_6 (Dropout)                (None, 4, 16, 64)       0            ['leaky_re_lu_13[0][0]']             
                                                                                                              
 conv2d_19 (Conv2D)                 (None, 4, 16, 64)       36928        ['dropout_6[0][0]']                  
                                                                                                              
 batch_normalization_14 (BatchNorma  (None, 4, 16, 64)      256          ['conv2d_19[0][0]']                  
 lization)                                                                                                    
                                                                                                              
 leaky_re_lu_14 (LeakyReLU)         (None, 4, 16, 64)       0            ['batch_normalization_14[0][0]']     
                                                                                                              
 conv2d_20 (Conv2D)                 (None, 4, 16, 64)       36928        ['leaky_re_lu_14[0][0]']             
                                                                                                              
 batch_normalization_15 (BatchNorma  (None, 4, 16, 64)      256          ['conv2d_20[0][0]']                  
 lization)                                                                                                    
                                                                                                              
 add_7 (Add)                        (None, 4, 16, 64)       0            ['batch_normalization_15[0][0]',     
                                                                          'dropout_6[0][0]']                  
                                                                                                              
 leaky_re_lu_15 (LeakyReLU)         (None, 4, 16, 64)       0            ['add_7[0][0]']                      
                                                                                                              
 dropout_7 (Dropout)                (None, 4, 16, 64)       0            ['leaky_re_lu_15[0][0]']             
                                                                                                              
 conv2d_21 (Conv2D)                 (None, 4, 16, 64)       36928        ['dropout_7[0][0]']                  
                                                                                                              
 batch_normalization_16 (BatchNorma  (None, 4, 16, 64)      256          ['conv2d_21[0][0]']                  
 lization)                                                                                                    
                                                                                                              
 leaky_re_lu_16 (LeakyReLU)         (None, 4, 16, 64)       0            ['batch_normalization_16[0][0]']     
                                                                                                              
 conv2d_22 (Conv2D)                 (None, 4, 16, 64)       36928        ['leaky_re_lu_16[0][0]']             
                                                                                                              
 batch_normalization_17 (BatchNorma  (None, 4, 16, 64)      256          ['conv2d_22[0][0]']                  
 lization)                                                                                                    
                                                                                                              
 add_8 (Add)                        (None, 4, 16, 64)       0            ['batch_normalization_17[0][0]',     
                                                                          'dropout_7[0][0]']                  
                                                                                                              
 leaky_re_lu_17 (LeakyReLU)         (None, 4, 16, 64)       0            ['add_8[0][0]']                      
                                                                                                              
 dropout_8 (Dropout)                (None, 4, 16, 64)       0            ['leaky_re_lu_17[0][0]']             
                                                                                                              
 reshape (Reshape)                  (None, 64, 64)          0            ['dropout_8[0][0]']                  
                                                                                                              
 bidirectional (Bidirectional)      (None, 64, 256)         197632       ['reshape[0][0]']                    
                                                                                                              
 dropout_9 (Dropout)                (None, 64, 256)         0            ['bidirectional[0][0]']              
                                                                                                              
 output (Dense)                     (None, 64, 79)          20303        ['dropout_9[0][0]']                  
                                                                                                              
==============================================================================================================
Total params: 549,455
Trainable params: 547,983
Non-trainable params: 1,472
______________________________________________________________________________________________________________
Epoch 1/150
5426/5426 [==============================] - ETA: 0s - loss: 13.0364 - CER: 1.0409 - WER: 0.9782
Epoch 1: val_CER improved from inf to 0.65181, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 259s 45ms/step - loss: 13.0364 - CER: 1.0409 - WER: 0.9782 - val_loss: 10.8146 - val_CER: 0.6518 - val_WER: 0.8406 - lr: 5.0000e-04
Epoch 2/150
5426/5426 [==============================] - ETA: 0s - loss: 9.1916 - CER: 0.6147 - WER: 0.8056
Epoch 2: val_CER improved from 0.65181 to 0.48610, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 237s 44ms/step - loss: 9.1916 - CER: 0.6146 - WER: 0.8056 - val_loss: 8.0200 - val_CER: 0.4861 - val_WER: 0.7408 - lr: 5.0000e-04
Epoch 3/150
5425/5426 [============================>.] - ETA: 0s - loss: 7.0913 - CER: 0.4606 - WER: 0.7190
Epoch 3: val_CER improved from 0.48610 to 0.35481, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 229s 42ms/step - loss: 7.0917 - CER: 0.4606 - WER: 0.7189 - val_loss: 6.0734 - val_CER: 0.3548 - val_WER: 0.6400 - lr: 5.0000e-04
Epoch 4/150
5426/5426 [==============================] - ETA: 0s - loss: 5.6692 - CER: 0.3537 - WER: 0.6399
Epoch 4: val_CER improved from 0.35481 to 0.23939, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 227s 42ms/step - loss: 5.6692 - CER: 0.3537 - WER: 0.6398 - val_loss: 4.1324 - val_CER: 0.2394 - val_WER: 0.5202 - lr: 5.0000e-04
Epoch 5/150
5425/5426 [============================>.] - ETA: 0s - loss: 4.8696 - CER: 0.2965 - WER: 0.5848
Epoch 5: val_CER improved from 0.23939 to 0.21560, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 227s 42ms/step - loss: 4.8703 - CER: 0.2965 - WER: 0.5848 - val_loss: 3.5850 - val_CER: 0.2156 - val_WER: 0.4872 - lr: 5.0000e-04
Epoch 6/150
5425/5426 [============================>.] - ETA: 0s - loss: 4.3796 - CER: 0.2651 - WER: 0.5444
Epoch 6: val_CER improved from 0.21560 to 0.19109, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 228s 42ms/step - loss: 4.3799 - CER: 0.2651 - WER: 0.5444 - val_loss: 3.1711 - val_CER: 0.1911 - val_WER: 0.4455 - lr: 5.0000e-04
Epoch 7/150
5426/5426 [==============================] - ETA: 0s - loss: 4.0379 - CER: 0.2426 - WER: 0.5138
Epoch 7: val_CER did not improve from 0.19109
5426/5426 [==============================] - 227s 42ms/step - loss: 4.0379 - CER: 0.2426 - WER: 0.5138 - val_loss: 4.7325 - val_CER: 0.2868 - val_WER: 0.5715 - lr: 5.0000e-04
Epoch 8/150
5426/5426 [==============================] - ETA: 0s - loss: 3.8287 - CER: 0.2293 - WER: 0.4991
Epoch 8: val_CER improved from 0.19109 to 0.16299, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 227s 42ms/step - loss: 3.8287 - CER: 0.2293 - WER: 0.4991 - val_loss: 2.6988 - val_CER: 0.1630 - val_WER: 0.3974 - lr: 5.0000e-04
Epoch 9/150
5426/5426 [==============================] - ETA: 0s - loss: 3.6186 - CER: 0.2172 - WER: 0.4810
Epoch 9: val_CER did not improve from 0.16299
5426/5426 [==============================] - 227s 42ms/step - loss: 3.6186 - CER: 0.2172 - WER: 0.4810 - val_loss: 2.7278 - val_CER: 0.1688 - val_WER: 0.4036 - lr: 5.0000e-04
Epoch 10/150
5426/5426 [==============================] - ETA: 0s - loss: 3.3817 - CER: 0.2036 - WER: 0.4627
Epoch 10: val_CER improved from 0.16299 to 0.14715, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 232s 43ms/step - loss: 3.3817 - CER: 0.2036 - WER: 0.4627 - val_loss: 2.4785 - val_CER: 0.1471 - val_WER: 0.3687 - lr: 5.0000e-04
Epoch 11/150
5426/5426 [==============================] - ETA: 0s - loss: 3.1978 - CER: 0.1929 - WER: 0.4461
Epoch 11: val_CER improved from 0.14715 to 0.14039, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 231s 42ms/step - loss: 3.1978 - CER: 0.1929 - WER: 0.4461 - val_loss: 2.3749 - val_CER: 0.1404 - val_WER: 0.3551 - lr: 5.0000e-04
Epoch 12/150
5425/5426 [============================>.] - ETA: 0s - loss: 3.0730 - CER: 0.1854 - WER: 0.4326
Epoch 12: val_CER improved from 0.14039 to 0.12999, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 230s 42ms/step - loss: 3.0726 - CER: 0.1854 - WER: 0.4326 - val_loss: 2.1714 - val_CER: 0.1300 - val_WER: 0.3348 - lr: 5.0000e-04
Epoch 13/150
5426/5426 [==============================] - ETA: 0s - loss: 2.9771 - CER: 0.1793 - WER: 0.4221
Epoch 13: val_CER did not improve from 0.12999
5426/5426 [==============================] - 229s 42ms/step - loss: 2.9771 - CER: 0.1793 - WER: 0.4221 - val_loss: 2.1993 - val_CER: 0.1316 - val_WER: 0.3344 - lr: 5.0000e-04
Epoch 14/150
5426/5426 [==============================] - ETA: 0s - loss: 2.8738 - CER: 0.1738 - WER: 0.4124
Epoch 14: val_CER improved from 0.12999 to 0.12611, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 230s 42ms/step - loss: 2.8738 - CER: 0.1738 - WER: 0.4124 - val_loss: 2.0936 - val_CER: 0.1261 - val_WER: 0.3189 - lr: 5.0000e-04
Epoch 15/150
5426/5426 [==============================] - ETA: 0s - loss: 2.7958 - CER: 0.1703 - WER: 0.4056
Epoch 15: val_CER did not improve from 0.12611
5426/5426 [==============================] - 229s 42ms/step - loss: 2.7958 - CER: 0.1703 - WER: 0.4056 - val_loss: 3.1143 - val_CER: 0.1878 - val_WER: 0.4152 - lr: 5.0000e-04
Epoch 16/150
5426/5426 [==============================] - ETA: 0s - loss: 2.7148 - CER: 0.1635 - WER: 0.3960
Epoch 16: val_CER improved from 0.12611 to 0.11833, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 229s 42ms/step - loss: 2.7148 - CER: 0.1635 - WER: 0.3960 - val_loss: 1.9738 - val_CER: 0.1183 - val_WER: 0.3080 - lr: 5.0000e-04
Epoch 17/150
5425/5426 [============================>.] - ETA: 0s - loss: 2.6579 - CER: 0.1598 - WER: 0.3883
Epoch 17: val_CER improved from 0.11833 to 0.11577, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 228s 42ms/step - loss: 2.6579 - CER: 0.1598 - WER: 0.3883 - val_loss: 1.9589 - val_CER: 0.1158 - val_WER: 0.3005 - lr: 5.0000e-04
Epoch 18/150
5426/5426 [==============================] - ETA: 0s - loss: 2.5966 - CER: 0.1569 - WER: 0.3809
Epoch 18: val_CER improved from 0.11577 to 0.11490, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 228s 42ms/step - loss: 2.5966 - CER: 0.1569 - WER: 0.3809 - val_loss: 1.9225 - val_CER: 0.1149 - val_WER: 0.3012 - lr: 5.0000e-04
Epoch 19/150
5426/5426 [==============================] - ETA: 0s - loss: 2.5250 - CER: 0.1517 - WER: 0.3737
Epoch 19: val_CER did not improve from 0.11490
5426/5426 [==============================] - 228s 42ms/step - loss: 2.5250 - CER: 0.1517 - WER: 0.3737 - val_loss: 2.1156 - val_CER: 0.1400 - val_WER: 0.3372 - lr: 5.0000e-04
Epoch 20/150
5425/5426 [============================>.] - ETA: 0s - loss: 2.4804 - CER: 0.1514 - WER: 0.3716
Epoch 20: val_CER did not improve from 0.11490
5426/5426 [==============================] - 228s 42ms/step - loss: 2.4806 - CER: 0.1514 - WER: 0.3716 - val_loss: 1.9476 - val_CER: 0.1158 - val_WER: 0.2988 - lr: 5.0000e-04
Epoch 21/150
5425/5426 [============================>.] - ETA: 0s - loss: 2.4353 - CER: 0.1483 - WER: 0.3674
Epoch 21: val_CER improved from 0.11490 to 0.10752, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 227s 42ms/step - loss: 2.4351 - CER: 0.1483 - WER: 0.3674 - val_loss: 1.7710 - val_CER: 0.1075 - val_WER: 0.2785 - lr: 5.0000e-04
Epoch 22/150
5425/5426 [============================>.] - ETA: 0s - loss: 2.3969 - CER: 0.1453 - WER: 0.3632
Epoch 22: val_CER did not improve from 0.10752
5426/5426 [==============================] - 226s 42ms/step - loss: 2.3966 - CER: 0.1453 - WER: 0.3632 - val_loss: 1.8888 - val_CER: 0.1170 - val_WER: 0.2994 - lr: 5.0000e-04
Epoch 23/150
5425/5426 [============================>.] - ETA: 0s - loss: 2.3678 - CER: 0.1437 - WER: 0.3581
Epoch 23: val_CER did not improve from 0.10752
5426/5426 [==============================] - 226s 42ms/step - loss: 2.3682 - CER: 0.1437 - WER: 0.3581 - val_loss: 1.8034 - val_CER: 0.1143 - val_WER: 0.2886 - lr: 5.0000e-04
Epoch 24/150
5426/5426 [==============================] - ETA: 0s - loss: 2.3149 - CER: 0.1409 - WER: 0.3541
Epoch 24: val_CER improved from 0.10752 to 0.10394, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 227s 42ms/step - loss: 2.3149 - CER: 0.1409 - WER: 0.3541 - val_loss: 1.6999 - val_CER: 0.1039 - val_WER: 0.2762 - lr: 5.0000e-04
Epoch 25/150
5425/5426 [============================>.] - ETA: 0s - loss: 2.2848 - CER: 0.1388 - WER: 0.3505
Epoch 25: val_CER did not improve from 0.10394
5426/5426 [==============================] - 226s 42ms/step - loss: 2.2846 - CER: 0.1388 - WER: 0.3505 - val_loss: 1.7758 - val_CER: 0.1062 - val_WER: 0.2768 - lr: 5.0000e-04
Epoch 26/150
5426/5426 [==============================] - ETA: 0s - loss: 2.2464 - CER: 0.1388 - WER: 0.3481
Epoch 26: val_CER improved from 0.10394 to 0.09987, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 226s 42ms/step - loss: 2.2464 - CER: 0.1388 - WER: 0.3481 - val_loss: 1.6830 - val_CER: 0.0999 - val_WER: 0.2657 - lr: 5.0000e-04
Epoch 27/150
5426/5426 [==============================] - ETA: 0s - loss: 2.2218 - CER: 0.1364 - WER: 0.3435
Epoch 27: val_CER improved from 0.09987 to 0.09808, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 226s 42ms/step - loss: 2.2218 - CER: 0.1364 - WER: 0.3435 - val_loss: 1.6356 - val_CER: 0.0981 - val_WER: 0.2592 - lr: 5.0000e-04
Epoch 28/150
5426/5426 [==============================] - ETA: 0s - loss: 2.2020 - CER: 0.1342 - WER: 0.3422
Epoch 28: val_CER improved from 0.09808 to 0.09775, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 226s 42ms/step - loss: 2.2020 - CER: 0.1342 - WER: 0.3422 - val_loss: 1.6249 - val_CER: 0.0977 - val_WER: 0.2579 - lr: 5.0000e-04
Epoch 29/150
5425/5426 [============================>.] - ETA: 0s - loss: 2.1746 - CER: 0.1324 - WER: 0.3393
Epoch 29: val_CER improved from 0.09775 to 0.09685, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 226s 42ms/step - loss: 2.1745 - CER: 0.1324 - WER: 0.3393 - val_loss: 1.6246 - val_CER: 0.0968 - val_WER: 0.2560 - lr: 5.0000e-04
Epoch 30/150
5426/5426 [==============================] - ETA: 0s - loss: 2.1386 - CER: 0.1317 - WER: 0.3357
Epoch 30: val_CER did not improve from 0.09685
5426/5426 [==============================] - 226s 42ms/step - loss: 2.1386 - CER: 0.1317 - WER: 0.3357 - val_loss: 1.6702 - val_CER: 0.0988 - val_WER: 0.2616 - lr: 5.0000e-04
Epoch 31/150
5426/5426 [==============================] - ETA: 0s - loss: 2.1230 - CER: 0.1275 - WER: 0.3284
Epoch 31: val_CER did not improve from 0.09685
5426/5426 [==============================] - 228s 42ms/step - loss: 2.1230 - CER: 0.1275 - WER: 0.3284 - val_loss: 1.8249 - val_CER: 0.1128 - val_WER: 0.2874 - lr: 5.0000e-04
Epoch 32/150
5426/5426 [==============================] - ETA: 0s - loss: 2.0943 - CER: 0.1283 - WER: 0.3284
Epoch 32: val_CER did not improve from 0.09685
5426/5426 [==============================] - 226s 42ms/step - loss: 2.0943 - CER: 0.1283 - WER: 0.3284 - val_loss: 1.6973 - val_CER: 0.1029 - val_WER: 0.2648 - lr: 5.0000e-04
Epoch 33/150
5426/5426 [==============================] - ETA: 0s - loss: 2.0820 - CER: 0.1261 - WER: 0.3278
Epoch 33: val_CER did not improve from 0.09685
5426/5426 [==============================] - 226s 42ms/step - loss: 2.0820 - CER: 0.1261 - WER: 0.3278 - val_loss: 1.6405 - val_CER: 0.0970 - val_WER: 0.2591 - lr: 5.0000e-04
Epoch 34/150
5426/5426 [==============================] - ETA: 0s - loss: 2.0538 - CER: 0.1245 - WER: 0.3230
Epoch 34: val_CER improved from 0.09685 to 0.09170, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 228s 42ms/step - loss: 2.0538 - CER: 0.1245 - WER: 0.3230 - val_loss: 1.5295 - val_CER: 0.0917 - val_WER: 0.2413 - lr: 5.0000e-04
Epoch 35/150
5425/5426 [============================>.] - ETA: 0s - loss: 2.0365 - CER: 0.1255 - WER: 0.3214
Epoch 35: val_CER did not improve from 0.09170
5426/5426 [==============================] - 226s 42ms/step - loss: 2.0366 - CER: 0.1255 - WER: 0.3214 - val_loss: 1.5722 - val_CER: 0.0931 - val_WER: 0.2448 - lr: 5.0000e-04
Epoch 36/150
5425/5426 [============================>.] - ETA: 0s - loss: 2.0328 - CER: 0.1264 - WER: 0.3249
Epoch 36: val_CER improved from 0.09170 to 0.09160, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 226s 42ms/step - loss: 2.0334 - CER: 0.1264 - WER: 0.3249 - val_loss: 1.5638 - val_CER: 0.0916 - val_WER: 0.2464 - lr: 5.0000e-04
Epoch 37/150
5426/5426 [==============================] - ETA: 0s - loss: 1.9923 - CER: 0.1224 - WER: 0.3164
Epoch 37: val_CER did not improve from 0.09160
5426/5426 [==============================] - 226s 42ms/step - loss: 1.9923 - CER: 0.1224 - WER: 0.3164 - val_loss: 1.9277 - val_CER: 0.1122 - val_WER: 0.2851 - lr: 5.0000e-04
Epoch 38/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.9930 - CER: 0.1230 - WER: 0.3176
Epoch 38: val_CER did not improve from 0.09160
5426/5426 [==============================] - 224s 41ms/step - loss: 1.9932 - CER: 0.1230 - WER: 0.3176 - val_loss: 1.5652 - val_CER: 0.0926 - val_WER: 0.2473 - lr: 5.0000e-04
Epoch 39/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.9613 - CER: 0.1204 - WER: 0.3119
Epoch 39: val_CER improved from 0.09160 to 0.09147, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 224s 41ms/step - loss: 1.9614 - CER: 0.1204 - WER: 0.3119 - val_loss: 1.5632 - val_CER: 0.0915 - val_WER: 0.2464 - lr: 5.0000e-04
Epoch 40/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.9472 - CER: 0.1195 - WER: 0.3093
Epoch 40: val_CER improved from 0.09147 to 0.08732, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 224s 41ms/step - loss: 1.9472 - CER: 0.1195 - WER: 0.3093 - val_loss: 1.4701 - val_CER: 0.0873 - val_WER: 0.2391 - lr: 5.0000e-04
Epoch 41/150
5426/5426 [==============================] - ETA: 0s - loss: 1.9360 - CER: 0.1200 - WER: 0.3089
Epoch 41: val_CER did not improve from 0.08732
5426/5426 [==============================] - 224s 41ms/step - loss: 1.9360 - CER: 0.1200 - WER: 0.3089 - val_loss: 1.7023 - val_CER: 0.1041 - val_WER: 0.2720 - lr: 5.0000e-04
Epoch 42/150
5426/5426 [==============================] - ETA: 0s - loss: 1.9255 - CER: 0.1175 - WER: 0.3087
Epoch 42: val_CER did not improve from 0.08732
5426/5426 [==============================] - 223s 41ms/step - loss: 1.9255 - CER: 0.1175 - WER: 0.3087 - val_loss: 1.6720 - val_CER: 0.1010 - val_WER: 0.2625 - lr: 5.0000e-04
Epoch 43/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.9029 - CER: 0.1185 - WER: 0.3089
Epoch 43: val_CER did not improve from 0.08732
5426/5426 [==============================] - 224s 41ms/step - loss: 1.9029 - CER: 0.1185 - WER: 0.3089 - val_loss: 1.7478 - val_CER: 0.1077 - val_WER: 0.2736 - lr: 5.0000e-04
Epoch 44/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.8964 - CER: 0.1182 - WER: 0.3088
Epoch 44: val_CER did not improve from 0.08732
5426/5426 [==============================] - 223s 41ms/step - loss: 1.8966 - CER: 0.1182 - WER: 0.3088 - val_loss: 1.4480 - val_CER: 0.0887 - val_WER: 0.2342 - lr: 5.0000e-04
Epoch 45/150
5426/5426 [==============================] - ETA: 0s - loss: 1.8860 - CER: 0.1148 - WER: 0.3010
Epoch 45: val_CER did not improve from 0.08732
5426/5426 [==============================] - 223s 41ms/step - loss: 1.8860 - CER: 0.1148 - WER: 0.3010 - val_loss: 1.4890 - val_CER: 0.0891 - val_WER: 0.2394 - lr: 5.0000e-04
Epoch 46/150
5426/5426 [==============================] - ETA: 0s - loss: 1.8610 - CER: 0.1142 - WER: 0.3033
Epoch 46: val_CER did not improve from 0.08732
5426/5426 [==============================] - 224s 41ms/step - loss: 1.8610 - CER: 0.1142 - WER: 0.3033 - val_loss: 1.4362 - val_CER: 0.0882 - val_WER: 0.2336 - lr: 5.0000e-04
Epoch 47/150
5426/5426 [==============================] - ETA: 0s - loss: 1.8441 - CER: 0.1139 - WER: 0.3001
Epoch 47: val_CER improved from 0.08732 to 0.08632, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 224s 41ms/step - loss: 1.8441 - CER: 0.1139 - WER: 0.3001 - val_loss: 1.4014 - val_CER: 0.0863 - val_WER: 0.2312 - lr: 5.0000e-04
Epoch 48/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.8320 - CER: 0.1138 - WER: 0.2983
Epoch 48: val_CER did not improve from 0.08632
5426/5426 [==============================] - 223s 41ms/step - loss: 1.8318 - CER: 0.1138 - WER: 0.2983 - val_loss: 1.4963 - val_CER: 0.0905 - val_WER: 0.2407 - lr: 5.0000e-04
Epoch 49/150
5426/5426 [==============================] - ETA: 0s - loss: 1.8363 - CER: 0.1127 - WER: 0.2964
Epoch 49: val_CER did not improve from 0.08632
5426/5426 [==============================] - 223s 41ms/step - loss: 1.8363 - CER: 0.1127 - WER: 0.2964 - val_loss: 1.5097 - val_CER: 0.0904 - val_WER: 0.2375 - lr: 5.0000e-04
Epoch 50/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.8233 - CER: 0.1137 - WER: 0.2965
Epoch 50: val_CER did not improve from 0.08632
5426/5426 [==============================] - 224s 41ms/step - loss: 1.8234 - CER: 0.1137 - WER: 0.2965 - val_loss: 1.4794 - val_CER: 0.0911 - val_WER: 0.2363 - lr: 5.0000e-04
Epoch 51/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.8122 - CER: 0.1133 - WER: 0.2982
Epoch 51: val_CER improved from 0.08632 to 0.08518, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 224s 41ms/step - loss: 1.8122 - CER: 0.1133 - WER: 0.2982 - val_loss: 1.4406 - val_CER: 0.0852 - val_WER: 0.2301 - lr: 5.0000e-04
Epoch 52/150
5426/5426 [==============================] - ETA: 0s - loss: 1.7961 - CER: 0.1116 - WER: 0.2935
Epoch 52: val_CER improved from 0.08518 to 0.08452, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 224s 41ms/step - loss: 1.7961 - CER: 0.1116 - WER: 0.2935 - val_loss: 1.4327 - val_CER: 0.0845 - val_WER: 0.2300 - lr: 5.0000e-04
Epoch 53/150
5426/5426 [==============================] - ETA: 0s - loss: 1.7762 - CER: 0.1091 - WER: 0.2907
Epoch 53: val_CER did not improve from 0.08452
5426/5426 [==============================] - 224s 41ms/step - loss: 1.7762 - CER: 0.1091 - WER: 0.2907 - val_loss: 1.4169 - val_CER: 0.0876 - val_WER: 0.2310 - lr: 5.0000e-04
Epoch 54/150
5426/5426 [==============================] - ETA: 0s - loss: 1.7778 - CER: 0.1105 - WER: 0.2896
Epoch 54: val_CER improved from 0.08452 to 0.08307, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 224s 41ms/step - loss: 1.7778 - CER: 0.1105 - WER: 0.2896 - val_loss: 1.3734 - val_CER: 0.0831 - val_WER: 0.2235 - lr: 5.0000e-04
Epoch 55/150
5426/5426 [==============================] - ETA: 0s - loss: 1.7546 - CER: 0.1107 - WER: 0.2908
Epoch 55: val_CER did not improve from 0.08307
5426/5426 [==============================] - 225s 41ms/step - loss: 1.7546 - CER: 0.1107 - WER: 0.2908 - val_loss: 1.4190 - val_CER: 0.0865 - val_WER: 0.2271 - lr: 5.0000e-04
Epoch 56/150
5426/5426 [==============================] - ETA: 0s - loss: 1.7529 - CER: 0.1102 - WER: 0.2923
Epoch 56: val_CER did not improve from 0.08307
5426/5426 [==============================] - 225s 41ms/step - loss: 1.7529 - CER: 0.1102 - WER: 0.2923 - val_loss: 1.3832 - val_CER: 0.0837 - val_WER: 0.2228 - lr: 5.0000e-04
Epoch 57/150
5426/5426 [==============================] - ETA: 0s - loss: 1.7433 - CER: 0.1080 - WER: 0.2871
Epoch 57: val_CER did not improve from 0.08307
5426/5426 [==============================] - 224s 41ms/step - loss: 1.7433 - CER: 0.1080 - WER: 0.2871 - val_loss: 1.6231 - val_CER: 0.0924 - val_WER: 0.2447 - lr: 5.0000e-04
Epoch 58/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.7366 - CER: 0.1071 - WER: 0.2863
Epoch 58: val_CER did not improve from 0.08307
5426/5426 [==============================] - 225s 41ms/step - loss: 1.7365 - CER: 0.1071 - WER: 0.2863 - val_loss: 1.3906 - val_CER: 0.0854 - val_WER: 0.2263 - lr: 5.0000e-04
Epoch 59/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.7356 - CER: 0.1081 - WER: 0.2853
Epoch 59: val_CER improved from 0.08307 to 0.08258, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 224s 41ms/step - loss: 1.7357 - CER: 0.1081 - WER: 0.2853 - val_loss: 1.3869 - val_CER: 0.0826 - val_WER: 0.2235 - lr: 5.0000e-04
Epoch 60/150
5426/5426 [==============================] - ETA: 0s - loss: 1.7192 - CER: 0.1065 - WER: 0.2824
Epoch 60: val_CER did not improve from 0.08258
5426/5426 [==============================] - 223s 41ms/step - loss: 1.7192 - CER: 0.1065 - WER: 0.2824 - val_loss: 1.4691 - val_CER: 0.0877 - val_WER: 0.2317 - lr: 5.0000e-04
Epoch 61/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.7045 - CER: 0.1075 - WER: 0.2842
Epoch 61: val_CER improved from 0.08258 to 0.08250, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 224s 41ms/step - loss: 1.7044 - CER: 0.1075 - WER: 0.2842 - val_loss: 1.4215 - val_CER: 0.0825 - val_WER: 0.2247 - lr: 5.0000e-04
Epoch 62/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.7013 - CER: 0.1073 - WER: 0.2872
Epoch 62: val_CER did not improve from 0.08250
5426/5426 [==============================] - 224s 41ms/step - loss: 1.7011 - CER: 0.1073 - WER: 0.2872 - val_loss: 1.6918 - val_CER: 0.0959 - val_WER: 0.2514 - lr: 5.0000e-04
Epoch 63/150
5426/5426 [==============================] - ETA: 0s - loss: 1.6770 - CER: 0.1049 - WER: 0.2811
Epoch 63: val_CER did not improve from 0.08250
5426/5426 [==============================] - 224s 41ms/step - loss: 1.6770 - CER: 0.1049 - WER: 0.2811 - val_loss: 1.5925 - val_CER: 0.0939 - val_WER: 0.2425 - lr: 5.0000e-04
Epoch 64/150
5426/5426 [==============================] - ETA: 0s - loss: 1.6826 - CER: 0.1056 - WER: 0.2813
Epoch 64: val_CER did not improve from 0.08250
5426/5426 [==============================] - 224s 41ms/step - loss: 1.6826 - CER: 0.1056 - WER: 0.2813 - val_loss: 1.3650 - val_CER: 0.0825 - val_WER: 0.2212 - lr: 5.0000e-04
Epoch 65/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.6701 - CER: 0.1051 - WER: 0.2801
Epoch 65: val_CER did not improve from 0.08250
5426/5426 [==============================] - 224s 41ms/step - loss: 1.6705 - CER: 0.1051 - WER: 0.2801 - val_loss: 1.4155 - val_CER: 0.0853 - val_WER: 0.2263 - lr: 5.0000e-04
Epoch 66/150
5426/5426 [==============================] - ETA: 0s - loss: 1.6720 - CER: 0.1046 - WER: 0.2787
Epoch 66: val_CER did not improve from 0.08250
5426/5426 [==============================] - 224s 41ms/step - loss: 1.6720 - CER: 0.1046 - WER: 0.2787 - val_loss: 1.3840 - val_CER: 0.0859 - val_WER: 0.2237 - lr: 5.0000e-04
Epoch 67/150
5426/5426 [==============================] - ETA: 0s - loss: 1.6631 - CER: 0.1051 - WER: 0.2781
Epoch 67: val_CER improved from 0.08250 to 0.08085, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 225s 41ms/step - loss: 1.6631 - CER: 0.1051 - WER: 0.2781 - val_loss: 1.3883 - val_CER: 0.0809 - val_WER: 0.2238 - lr: 5.0000e-04
Epoch 68/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.6438 - CER: 0.1041 - WER: 0.2801
Epoch 68: val_CER improved from 0.08085 to 0.08069, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 224s 41ms/step - loss: 1.6438 - CER: 0.1041 - WER: 0.2801 - val_loss: 1.3602 - val_CER: 0.0807 - val_WER: 0.2173 - lr: 5.0000e-04
Epoch 69/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.6589 - CER: 0.1058 - WER: 0.2771
Epoch 69: val_CER did not improve from 0.08069
5426/5426 [==============================] - 224s 41ms/step - loss: 1.6593 - CER: 0.1058 - WER: 0.2771 - val_loss: 1.4080 - val_CER: 0.0833 - val_WER: 0.2238 - lr: 5.0000e-04
Epoch 70/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.6366 - CER: 0.1019 - WER: 0.2733
Epoch 70: val_CER improved from 0.08069 to 0.07932, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 224s 41ms/step - loss: 1.6368 - CER: 0.1019 - WER: 0.2733 - val_loss: 1.3076 - val_CER: 0.0793 - val_WER: 0.2145 - lr: 5.0000e-04
Epoch 71/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.6326 - CER: 0.1047 - WER: 0.2775
Epoch 71: val_CER did not improve from 0.07932
5426/5426 [==============================] - 224s 41ms/step - loss: 1.6324 - CER: 0.1047 - WER: 0.2775 - val_loss: 1.3297 - val_CER: 0.0796 - val_WER: 0.2143 - lr: 5.0000e-04
Epoch 72/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.6292 - CER: 0.1031 - WER: 0.2747
Epoch 72: val_CER did not improve from 0.07932
5426/5426 [==============================] - 224s 41ms/step - loss: 1.6291 - CER: 0.1031 - WER: 0.2747 - val_loss: 1.3923 - val_CER: 0.0832 - val_WER: 0.2206 - lr: 5.0000e-04
Epoch 73/150
5426/5426 [==============================] - ETA: 0s - loss: 1.6167 - CER: 0.1024 - WER: 0.2738
Epoch 73: val_CER did not improve from 0.07932
5426/5426 [==============================] - 224s 41ms/step - loss: 1.6167 - CER: 0.1024 - WER: 0.2738 - val_loss: 1.3304 - val_CER: 0.0795 - val_WER: 0.2145 - lr: 5.0000e-04
Epoch 74/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.6055 - CER: 0.1011 - WER: 0.2713
Epoch 74: val_CER did not improve from 0.07932
5426/5426 [==============================] - 224s 41ms/step - loss: 1.6055 - CER: 0.1011 - WER: 0.2713 - val_loss: 1.3808 - val_CER: 0.0802 - val_WER: 0.2163 - lr: 5.0000e-04
Epoch 75/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.5985 - CER: 0.1010 - WER: 0.2699
Epoch 75: val_CER did not improve from 0.07932
5426/5426 [==============================] - 224s 41ms/step - loss: 1.5985 - CER: 0.1010 - WER: 0.2699 - val_loss: 1.3464 - val_CER: 0.0804 - val_WER: 0.2150 - lr: 5.0000e-04
Epoch 76/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.6083 - CER: 0.1037 - WER: 0.2749
Epoch 76: val_CER did not improve from 0.07932
5426/5426 [==============================] - 224s 41ms/step - loss: 1.6086 - CER: 0.1037 - WER: 0.2749 - val_loss: 1.3474 - val_CER: 0.0802 - val_WER: 0.2138 - lr: 5.0000e-04
Epoch 77/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.6069 - CER: 0.1016 - WER: 0.2700
Epoch 77: val_CER improved from 0.07932 to 0.07857, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 225s 41ms/step - loss: 1.6068 - CER: 0.1016 - WER: 0.2700 - val_loss: 1.3185 - val_CER: 0.0786 - val_WER: 0.2119 - lr: 5.0000e-04
Epoch 78/150
5426/5426 [==============================] - ETA: 0s - loss: 1.5867 - CER: 0.0990 - WER: 0.2674
Epoch 78: val_CER did not improve from 0.07857
5426/5426 [==============================] - 224s 41ms/step - loss: 1.5867 - CER: 0.0990 - WER: 0.2674 - val_loss: 1.3285 - val_CER: 0.0791 - val_WER: 0.2106 - lr: 5.0000e-04
Epoch 79/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.5779 - CER: 0.0993 - WER: 0.2676
Epoch 79: val_CER did not improve from 0.07857
5426/5426 [==============================] - 224s 41ms/step - loss: 1.5782 - CER: 0.0993 - WER: 0.2676 - val_loss: 1.3626 - val_CER: 0.0788 - val_WER: 0.2143 - lr: 5.0000e-04
Epoch 80/150
5426/5426 [==============================] - ETA: 0s - loss: 1.5805 - CER: 0.0994 - WER: 0.2673
Epoch 80: val_CER did not improve from 0.07857
5426/5426 [==============================] - 224s 41ms/step - loss: 1.5805 - CER: 0.0994 - WER: 0.2673 - val_loss: 1.3385 - val_CER: 0.0806 - val_WER: 0.2137 - lr: 5.0000e-04
Epoch 81/150
5426/5426 [==============================] - ETA: 0s - loss: 1.5629 - CER: 0.0987 - WER: 0.2669
Epoch 81: val_CER did not improve from 0.07857
5426/5426 [==============================] - 225s 41ms/step - loss: 1.5629 - CER: 0.0987 - WER: 0.2669 - val_loss: 1.4345 - val_CER: 0.0842 - val_WER: 0.2256 - lr: 5.0000e-04
Epoch 82/150
5426/5426 [==============================] - ETA: 0s - loss: 1.5655 - CER: 0.0983 - WER: 0.2659
Epoch 82: val_CER did not improve from 0.07857
5426/5426 [==============================] - 232s 43ms/step - loss: 1.5655 - CER: 0.0983 - WER: 0.2659 - val_loss: 1.3366 - val_CER: 0.0789 - val_WER: 0.2111 - lr: 5.0000e-04
Epoch 83/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.5534 - CER: 0.0980 - WER: 0.2636
Epoch 83: val_CER did not improve from 0.07857
5426/5426 [==============================] - 226s 42ms/step - loss: 1.5533 - CER: 0.0980 - WER: 0.2636 - val_loss: 1.4345 - val_CER: 0.0851 - val_WER: 0.2206 - lr: 5.0000e-04
Epoch 84/150
5426/5426 [==============================] - ETA: 0s - loss: 1.5518 - CER: 0.0983 - WER: 0.2648
Epoch 84: val_CER did not improve from 0.07857
5426/5426 [==============================] - 226s 42ms/step - loss: 1.5518 - CER: 0.0983 - WER: 0.2648 - val_loss: 1.4830 - val_CER: 0.0892 - val_WER: 0.2324 - lr: 5.0000e-04
Epoch 85/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.5357 - CER: 0.0990 - WER: 0.2633
Epoch 85: val_CER did not improve from 0.07857
5426/5426 [==============================] - 226s 42ms/step - loss: 1.5357 - CER: 0.0990 - WER: 0.2633 - val_loss: 1.3224 - val_CER: 0.0786 - val_WER: 0.2124 - lr: 5.0000e-04
Epoch 86/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.5338 - CER: 0.0972 - WER: 0.2626
Epoch 86: val_CER did not improve from 0.07857
5426/5426 [==============================] - 225s 41ms/step - loss: 1.5338 - CER: 0.0972 - WER: 0.2626 - val_loss: 1.3559 - val_CER: 0.0826 - val_WER: 0.2153 - lr: 5.0000e-04
Epoch 87/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.5350 - CER: 0.0976 - WER: 0.2613
Epoch 87: val_CER improved from 0.07857 to 0.07803, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 226s 42ms/step - loss: 1.5350 - CER: 0.0976 - WER: 0.2613 - val_loss: 1.3045 - val_CER: 0.0780 - val_WER: 0.2085 - lr: 5.0000e-04
Epoch 88/150
5426/5426 [==============================] - ETA: 0s - loss: 1.5366 - CER: 0.0978 - WER: 0.2634
Epoch 88: val_CER did not improve from 0.07803
5426/5426 [==============================] - 225s 41ms/step - loss: 1.5366 - CER: 0.0978 - WER: 0.2634 - val_loss: 1.2941 - val_CER: 0.0781 - val_WER: 0.2074 - lr: 5.0000e-04
Epoch 89/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.5247 - CER: 0.0969 - WER: 0.2598
Epoch 89: val_CER improved from 0.07803 to 0.07770, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 225s 41ms/step - loss: 1.5248 - CER: 0.0969 - WER: 0.2598 - val_loss: 1.3054 - val_CER: 0.0777 - val_WER: 0.2114 - lr: 5.0000e-04
Epoch 90/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.5042 - CER: 0.0938 - WER: 0.2572
Epoch 90: val_CER improved from 0.07770 to 0.07526, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 225s 41ms/step - loss: 1.5041 - CER: 0.0938 - WER: 0.2572 - val_loss: 1.2815 - val_CER: 0.0753 - val_WER: 0.2071 - lr: 5.0000e-04
Epoch 91/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.5135 - CER: 0.0964 - WER: 0.2612
Epoch 91: val_CER did not improve from 0.07526
5426/5426 [==============================] - 224s 41ms/step - loss: 1.5136 - CER: 0.0964 - WER: 0.2612 - val_loss: 1.2994 - val_CER: 0.0779 - val_WER: 0.2077 - lr: 5.0000e-04
Epoch 92/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.5104 - CER: 0.0969 - WER: 0.2602
Epoch 92: val_CER did not improve from 0.07526
5426/5426 [==============================] - 224s 41ms/step - loss: 1.5102 - CER: 0.0969 - WER: 0.2602 - val_loss: 1.3350 - val_CER: 0.0788 - val_WER: 0.2093 - lr: 5.0000e-04
Epoch 93/150
5426/5426 [==============================] - ETA: 0s - loss: 1.5113 - CER: 0.0966 - WER: 0.2602
Epoch 93: val_CER did not improve from 0.07526
5426/5426 [==============================] - 229s 42ms/step - loss: 1.5113 - CER: 0.0966 - WER: 0.2602 - val_loss: 1.2688 - val_CER: 0.0759 - val_WER: 0.2030 - lr: 5.0000e-04
Epoch 94/150
5426/5426 [==============================] - ETA: 0s - loss: 1.4913 - CER: 0.0952 - WER: 0.2584
Epoch 94: val_CER did not improve from 0.07526
5426/5426 [==============================] - 226s 42ms/step - loss: 1.4913 - CER: 0.0952 - WER: 0.2584 - val_loss: 1.2648 - val_CER: 0.0757 - val_WER: 0.2007 - lr: 5.0000e-04
Epoch 95/150
5426/5426 [==============================] - ETA: 0s - loss: 1.4958 - CER: 0.0959 - WER: 0.2608
Epoch 95: val_CER did not improve from 0.07526
5426/5426 [==============================] - 231s 43ms/step - loss: 1.4958 - CER: 0.0959 - WER: 0.2608 - val_loss: 1.3138 - val_CER: 0.0783 - val_WER: 0.2104 - lr: 5.0000e-04
Epoch 96/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.4902 - CER: 0.0962 - WER: 0.2591
Epoch 96: val_CER did not improve from 0.07526
5426/5426 [==============================] - 230s 42ms/step - loss: 1.4902 - CER: 0.0962 - WER: 0.2591 - val_loss: 1.3956 - val_CER: 0.0799 - val_WER: 0.2108 - lr: 5.0000e-04
Epoch 97/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.4870 - CER: 0.0953 - WER: 0.2574
Epoch 97: val_CER did not improve from 0.07526
5426/5426 [==============================] - 229s 42ms/step - loss: 1.4869 - CER: 0.0953 - WER: 0.2574 - val_loss: 1.4331 - val_CER: 0.0853 - val_WER: 0.2240 - lr: 5.0000e-04
Epoch 98/150
5426/5426 [==============================] - ETA: 0s - loss: 1.4800 - CER: 0.0944 - WER: 0.2553
Epoch 98: val_CER did not improve from 0.07526
5426/5426 [==============================] - 226s 42ms/step - loss: 1.4800 - CER: 0.0944 - WER: 0.2553 - val_loss: 1.2691 - val_CER: 0.0775 - val_WER: 0.2050 - lr: 5.0000e-04
Epoch 99/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.4824 - CER: 0.0940 - WER: 0.2544
Epoch 99: val_CER improved from 0.07526 to 0.07479, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 229s 42ms/step - loss: 1.4825 - CER: 0.0940 - WER: 0.2544 - val_loss: 1.2509 - val_CER: 0.0748 - val_WER: 0.2009 - lr: 5.0000e-04
Epoch 100/150
5426/5426 [==============================] - ETA: 0s - loss: 1.4663 - CER: 0.0913 - WER: 0.2513
Epoch 100: val_CER did not improve from 0.07479
5426/5426 [==============================] - 229s 42ms/step - loss: 1.4663 - CER: 0.0913 - WER: 0.2513 - val_loss: 1.3198 - val_CER: 0.0770 - val_WER: 0.2079 - lr: 5.0000e-04
Epoch 101/150
5426/5426 [==============================] - ETA: 0s - loss: 1.4699 - CER: 0.0936 - WER: 0.2544
Epoch 101: val_CER did not improve from 0.07479
5426/5426 [==============================] - 226s 42ms/step - loss: 1.4699 - CER: 0.0936 - WER: 0.2544 - val_loss: 1.3549 - val_CER: 0.0792 - val_WER: 0.2121 - lr: 5.0000e-04
Epoch 102/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.4656 - CER: 0.0943 - WER: 0.2544
Epoch 102: val_CER did not improve from 0.07479
5426/5426 [==============================] - 225s 41ms/step - loss: 1.4656 - CER: 0.0943 - WER: 0.2544 - val_loss: 1.3304 - val_CER: 0.0789 - val_WER: 0.2115 - lr: 5.0000e-04
Epoch 103/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.4586 - CER: 0.0928 - WER: 0.2538
Epoch 103: val_CER did not improve from 0.07479
5426/5426 [==============================] - 225s 41ms/step - loss: 1.4586 - CER: 0.0928 - WER: 0.2538 - val_loss: 1.4003 - val_CER: 0.0889 - val_WER: 0.2270 - lr: 5.0000e-04
Epoch 104/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.4641 - CER: 0.0932 - WER: 0.2517
Epoch 104: val_CER improved from 0.07479 to 0.07393, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 224s 41ms/step - loss: 1.4639 - CER: 0.0932 - WER: 0.2517 - val_loss: 1.2550 - val_CER: 0.0739 - val_WER: 0.1980 - lr: 5.0000e-04
Epoch 105/150
5426/5426 [==============================] - ETA: 0s - loss: 1.4460 - CER: 0.0922 - WER: 0.2512
Epoch 105: val_CER did not improve from 0.07393
5426/5426 [==============================] - 224s 41ms/step - loss: 1.4460 - CER: 0.0922 - WER: 0.2512 - val_loss: 1.2738 - val_CER: 0.0744 - val_WER: 0.2019 - lr: 5.0000e-04
Epoch 106/150
5426/5426 [==============================] - ETA: 0s - loss: 1.4402 - CER: 0.0916 - WER: 0.2497
Epoch 106: val_CER did not improve from 0.07393
5426/5426 [==============================] - 224s 41ms/step - loss: 1.4402 - CER: 0.0916 - WER: 0.2497 - val_loss: 1.2882 - val_CER: 0.0751 - val_WER: 0.2014 - lr: 5.0000e-04
Epoch 107/150
5426/5426 [==============================] - ETA: 0s - loss: 1.4410 - CER: 0.0917 - WER: 0.2488
Epoch 107: val_CER did not improve from 0.07393
5426/5426 [==============================] - 224s 41ms/step - loss: 1.4410 - CER: 0.0917 - WER: 0.2488 - val_loss: 1.3192 - val_CER: 0.0782 - val_WER: 0.2100 - lr: 5.0000e-04
Epoch 108/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.4496 - CER: 0.0934 - WER: 0.2526
Epoch 108: val_CER did not improve from 0.07393
5426/5426 [==============================] - 224s 41ms/step - loss: 1.4494 - CER: 0.0934 - WER: 0.2526 - val_loss: 1.2731 - val_CER: 0.0757 - val_WER: 0.2019 - lr: 5.0000e-04
Epoch 109/150
5426/5426 [==============================] - ETA: 0s - loss: 1.4369 - CER: 0.0913 - WER: 0.2472
Epoch 109: val_CER did not improve from 0.07393
5426/5426 [==============================] - 224s 41ms/step - loss: 1.4369 - CER: 0.0913 - WER: 0.2472 - val_loss: 1.3073 - val_CER: 0.0755 - val_WER: 0.2026 - lr: 5.0000e-04
Epoch 110/150
5426/5426 [==============================] - ETA: 0s - loss: 1.4399 - CER: 0.0920 - WER: 0.2506
Epoch 110: val_CER improved from 0.07393 to 0.07381, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 222s 41ms/step - loss: 1.4399 - CER: 0.0920 - WER: 0.2506 - val_loss: 1.2473 - val_CER: 0.0738 - val_WER: 0.1994 - lr: 5.0000e-04
Epoch 111/150
5426/5426 [==============================] - ETA: 0s - loss: 1.4349 - CER: 0.0911 - WER: 0.2499
Epoch 111: val_CER did not improve from 0.07381
5426/5426 [==============================] - 221s 41ms/step - loss: 1.4349 - CER: 0.0911 - WER: 0.2499 - val_loss: 1.2773 - val_CER: 0.0745 - val_WER: 0.2027 - lr: 5.0000e-04
Epoch 112/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.4214 - CER: 0.0909 - WER: 0.2475
Epoch 112: val_CER did not improve from 0.07381
5426/5426 [==============================] - 221s 41ms/step - loss: 1.4213 - CER: 0.0909 - WER: 0.2475 - val_loss: 1.2529 - val_CER: 0.0752 - val_WER: 0.2009 - lr: 5.0000e-04
Epoch 113/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.4174 - CER: 0.0919 - WER: 0.2478
Epoch 113: val_CER did not improve from 0.07381
5426/5426 [==============================] - 222s 41ms/step - loss: 1.4175 - CER: 0.0919 - WER: 0.2478 - val_loss: 1.2523 - val_CER: 0.0744 - val_WER: 0.2003 - lr: 5.0000e-04
Epoch 114/150
5426/5426 [==============================] - ETA: 0s - loss: 1.4149 - CER: 0.0898 - WER: 0.2472
Epoch 114: val_CER did not improve from 0.07381
5426/5426 [==============================] - 222s 41ms/step - loss: 1.4149 - CER: 0.0898 - WER: 0.2472 - val_loss: 1.3110 - val_CER: 0.0768 - val_WER: 0.2064 - lr: 5.0000e-04
Epoch 115/150
5426/5426 [==============================] - ETA: 0s - loss: 1.4150 - CER: 0.0912 - WER: 0.2481
Epoch 115: val_CER did not improve from 0.07381
5426/5426 [==============================] - 224s 41ms/step - loss: 1.4150 - CER: 0.0912 - WER: 0.2481 - val_loss: 1.2379 - val_CER: 0.0739 - val_WER: 0.1983 - lr: 5.0000e-04
Epoch 116/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.4243 - CER: 0.0912 - WER: 0.2446
Epoch 116: val_CER did not improve from 0.07381
5426/5426 [==============================] - 225s 41ms/step - loss: 1.4245 - CER: 0.0912 - WER: 0.2446 - val_loss: 1.2592 - val_CER: 0.0755 - val_WER: 0.2026 - lr: 5.0000e-04
Epoch 117/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.4140 - CER: 0.0895 - WER: 0.2451
Epoch 117: val_CER did not improve from 0.07381
5426/5426 [==============================] - 222s 41ms/step - loss: 1.4141 - CER: 0.0895 - WER: 0.2451 - val_loss: 1.5690 - val_CER: 0.0905 - val_WER: 0.2329 - lr: 5.0000e-04
Epoch 118/150
5426/5426 [==============================] - ETA: 0s - loss: 1.4071 - CER: 0.0898 - WER: 0.2442
Epoch 118: val_CER did not improve from 0.07381
5426/5426 [==============================] - 224s 41ms/step - loss: 1.4071 - CER: 0.0898 - WER: 0.2442 - val_loss: 1.2078 - val_CER: 0.0747 - val_WER: 0.1978 - lr: 5.0000e-04
Epoch 119/150
5426/5426 [==============================] - ETA: 0s - loss: 1.4087 - CER: 0.0914 - WER: 0.2484
Epoch 119: val_CER improved from 0.07381 to 0.07332, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 227s 42ms/step - loss: 1.4087 - CER: 0.0914 - WER: 0.2484 - val_loss: 1.2497 - val_CER: 0.0733 - val_WER: 0.1978 - lr: 5.0000e-04
Epoch 120/150
5426/5426 [==============================] - ETA: 0s - loss: 1.3937 - CER: 0.0898 - WER: 0.2444
Epoch 120: val_CER did not improve from 0.07332
5426/5426 [==============================] - 222s 41ms/step - loss: 1.3937 - CER: 0.0898 - WER: 0.2444 - val_loss: 1.2177 - val_CER: 0.0733 - val_WER: 0.1956 - lr: 5.0000e-04
Epoch 121/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.3881 - CER: 0.0889 - WER: 0.2432
Epoch 121: val_CER improved from 0.07332 to 0.07286, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 227s 42ms/step - loss: 1.3883 - CER: 0.0889 - WER: 0.2432 - val_loss: 1.2044 - val_CER: 0.0729 - val_WER: 0.1938 - lr: 5.0000e-04
Epoch 122/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.3975 - CER: 0.0908 - WER: 0.2461
Epoch 122: val_CER did not improve from 0.07286
5426/5426 [==============================] - 222s 41ms/step - loss: 1.3974 - CER: 0.0908 - WER: 0.2461 - val_loss: 1.2511 - val_CER: 0.0748 - val_WER: 0.1987 - lr: 5.0000e-04
Epoch 123/150
5426/5426 [==============================] - ETA: 0s - loss: 1.3953 - CER: 0.0897 - WER: 0.2430
Epoch 123: val_CER improved from 0.07286 to 0.07249, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 222s 41ms/step - loss: 1.3953 - CER: 0.0897 - WER: 0.2430 - val_loss: 1.2507 - val_CER: 0.0725 - val_WER: 0.1956 - lr: 5.0000e-04
Epoch 124/150
5426/5426 [==============================] - ETA: 0s - loss: 1.3824 - CER: 0.0892 - WER: 0.2451
Epoch 124: val_CER did not improve from 0.07249
5426/5426 [==============================] - 222s 41ms/step - loss: 1.3824 - CER: 0.0892 - WER: 0.2451 - val_loss: 1.2380 - val_CER: 0.0726 - val_WER: 0.1958 - lr: 5.0000e-04
Epoch 125/150
5426/5426 [==============================] - ETA: 0s - loss: 1.3905 - CER: 0.0906 - WER: 0.2453
Epoch 125: val_CER improved from 0.07249 to 0.07126, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 222s 41ms/step - loss: 1.3905 - CER: 0.0906 - WER: 0.2453 - val_loss: 1.2025 - val_CER: 0.0713 - val_WER: 0.1910 - lr: 5.0000e-04
Epoch 126/150
5426/5426 [==============================] - ETA: 0s - loss: 1.3785 - CER: 0.0877 - WER: 0.2401
Epoch 126: val_CER did not improve from 0.07126
5426/5426 [==============================] - 221s 41ms/step - loss: 1.3785 - CER: 0.0877 - WER: 0.2401 - val_loss: 1.1953 - val_CER: 0.0716 - val_WER: 0.1903 - lr: 5.0000e-04
Epoch 127/150
5426/5426 [==============================] - ETA: 0s - loss: 1.3754 - CER: 0.0896 - WER: 0.2430
Epoch 127: val_CER did not improve from 0.07126
5426/5426 [==============================] - 222s 41ms/step - loss: 1.3754 - CER: 0.0896 - WER: 0.2430 - val_loss: 1.3000 - val_CER: 0.0771 - val_WER: 0.2019 - lr: 5.0000e-04
Epoch 128/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.3701 - CER: 0.0882 - WER: 0.2421
Epoch 128: val_CER did not improve from 0.07126
5426/5426 [==============================] - 221s 41ms/step - loss: 1.3701 - CER: 0.0882 - WER: 0.2421 - val_loss: 1.3522 - val_CER: 0.0794 - val_WER: 0.2082 - lr: 5.0000e-04
Epoch 129/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.3625 - CER: 0.0870 - WER: 0.2397
Epoch 129: val_CER did not improve from 0.07126
5426/5426 [==============================] - 221s 41ms/step - loss: 1.3627 - CER: 0.0870 - WER: 0.2397 - val_loss: 1.2177 - val_CER: 0.0737 - val_WER: 0.1936 - lr: 5.0000e-04
Epoch 130/150
5426/5426 [==============================] - ETA: 0s - loss: 1.3537 - CER: 0.0868 - WER: 0.2390
Epoch 130: val_CER did not improve from 0.07126
5426/5426 [==============================] - 223s 41ms/step - loss: 1.3537 - CER: 0.0868 - WER: 0.2390 - val_loss: 1.2053 - val_CER: 0.0726 - val_WER: 0.1942 - lr: 5.0000e-04
Epoch 131/150
5426/5426 [==============================] - ETA: 0s - loss: 1.3604 - CER: 0.0880 - WER: 0.2408
Epoch 131: val_CER did not improve from 0.07126
5426/5426 [==============================] - 234s 43ms/step - loss: 1.3604 - CER: 0.0880 - WER: 0.2408 - val_loss: 1.2021 - val_CER: 0.0726 - val_WER: 0.1930 - lr: 5.0000e-04
Epoch 132/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.3534 - CER: 0.0875 - WER: 0.2398
Epoch 132: val_CER did not improve from 0.07126
5426/5426 [==============================] - 222s 41ms/step - loss: 1.3532 - CER: 0.0875 - WER: 0.2398 - val_loss: 1.2361 - val_CER: 0.0754 - val_WER: 0.1970 - lr: 5.0000e-04
Epoch 133/150
5426/5426 [==============================] - ETA: 0s - loss: 1.3450 - CER: 0.0861 - WER: 0.2389
Epoch 133: val_CER did not improve from 0.07126
5426/5426 [==============================] - 221s 41ms/step - loss: 1.3450 - CER: 0.0861 - WER: 0.2389 - val_loss: 1.2268 - val_CER: 0.0716 - val_WER: 0.1951 - lr: 5.0000e-04
Epoch 134/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.3561 - CER: 0.0863 - WER: 0.2370
Epoch 134: val_CER did not improve from 0.07126
5426/5426 [==============================] - 224s 41ms/step - loss: 1.3560 - CER: 0.0863 - WER: 0.2370 - val_loss: 1.1999 - val_CER: 0.0739 - val_WER: 0.1933 - lr: 5.0000e-04
Epoch 135/150
5426/5426 [==============================] - ETA: 0s - loss: 1.3430 - CER: 0.0877 - WER: 0.2380
Epoch 135: val_CER did not improve from 0.07126

Epoch 135: ReduceLROnPlateau reducing learning rate to 0.0004500000213738531.
5426/5426 [==============================] - 227s 42ms/step - loss: 1.3430 - CER: 0.0877 - WER: 0.2380 - val_loss: 1.2386 - val_CER: 0.0756 - val_WER: 0.1968 - lr: 5.0000e-04
Epoch 136/150
5426/5426 [==============================] - ETA: 0s - loss: 1.3294 - CER: 0.0881 - WER: 0.2388
Epoch 136: val_CER improved from 0.07126 to 0.07009, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 228s 42ms/step - loss: 1.3294 - CER: 0.0881 - WER: 0.2388 - val_loss: 1.2123 - val_CER: 0.0701 - val_WER: 0.1902 - lr: 4.5000e-04
Epoch 137/150
5426/5426 [==============================] - ETA: 0s - loss: 1.3161 - CER: 0.0829 - WER: 0.2306
Epoch 137: val_CER did not improve from 0.07009
5426/5426 [==============================] - 227s 42ms/step - loss: 1.3161 - CER: 0.0829 - WER: 0.2306 - val_loss: 1.2139 - val_CER: 0.0728 - val_WER: 0.1915 - lr: 4.5000e-04
Epoch 138/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.3203 - CER: 0.0855 - WER: 0.2353
Epoch 138: val_CER did not improve from 0.07009
5426/5426 [==============================] - 228s 42ms/step - loss: 1.3203 - CER: 0.0855 - WER: 0.2353 - val_loss: 1.2344 - val_CER: 0.0737 - val_WER: 0.1927 - lr: 4.5000e-04
Epoch 139/150
5426/5426 [==============================] - ETA: 0s - loss: 1.3041 - CER: 0.0838 - WER: 0.2311
Epoch 139: val_CER did not improve from 0.07009
5426/5426 [==============================] - 228s 42ms/step - loss: 1.3041 - CER: 0.0838 - WER: 0.2311 - val_loss: 1.2231 - val_CER: 0.0714 - val_WER: 0.1922 - lr: 4.5000e-04
Epoch 140/150
5426/5426 [==============================] - ETA: 0s - loss: 1.3111 - CER: 0.0854 - WER: 0.2350
Epoch 140: val_CER did not improve from 0.07009
5426/5426 [==============================] - 229s 42ms/step - loss: 1.3111 - CER: 0.0854 - WER: 0.2350 - val_loss: 1.2019 - val_CER: 0.0711 - val_WER: 0.1896 - lr: 4.5000e-04
Epoch 141/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.2956 - CER: 0.0829 - WER: 0.2283
Epoch 141: val_CER did not improve from 0.07009
5426/5426 [==============================] - 228s 42ms/step - loss: 1.2957 - CER: 0.0829 - WER: 0.2283 - val_loss: 1.2013 - val_CER: 0.0718 - val_WER: 0.1905 - lr: 4.5000e-04
Epoch 142/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.2909 - CER: 0.0835 - WER: 0.2306
Epoch 142: val_CER did not improve from 0.07009
5426/5426 [==============================] - 228s 42ms/step - loss: 1.2908 - CER: 0.0835 - WER: 0.2306 - val_loss: 1.1921 - val_CER: 0.0709 - val_WER: 0.1884 - lr: 4.5000e-04
Epoch 143/150
5426/5426 [==============================] - ETA: 0s - loss: 1.2976 - CER: 0.0837 - WER: 0.2337
Epoch 143: val_CER did not improve from 0.07009
5426/5426 [==============================] - 229s 42ms/step - loss: 1.2976 - CER: 0.0837 - WER: 0.2337 - val_loss: 1.2424 - val_CER: 0.0759 - val_WER: 0.1985 - lr: 4.5000e-04
Epoch 144/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.2927 - CER: 0.0848 - WER: 0.2320
Epoch 144: val_CER did not improve from 0.07009
5426/5426 [==============================] - 229s 42ms/step - loss: 1.2926 - CER: 0.0848 - WER: 0.2320 - val_loss: 1.2062 - val_CER: 0.0732 - val_WER: 0.1926 - lr: 4.5000e-04
Epoch 145/150
5426/5426 [==============================] - ETA: 0s - loss: 1.2878 - CER: 0.0818 - WER: 0.2269
Epoch 145: val_CER did not improve from 0.07009
5426/5426 [==============================] - 233s 43ms/step - loss: 1.2878 - CER: 0.0818 - WER: 0.2269 - val_loss: 1.2162 - val_CER: 0.0727 - val_WER: 0.1906 - lr: 4.5000e-04
Epoch 146/150
5426/5426 [==============================] - ETA: 0s - loss: 1.2907 - CER: 0.0854 - WER: 0.2330
Epoch 146: val_CER did not improve from 0.07009

Epoch 146: ReduceLROnPlateau reducing learning rate to 0.0004050000192364678.
5426/5426 [==============================] - 229s 42ms/step - loss: 1.2907 - CER: 0.0854 - WER: 0.2330 - val_loss: 1.1868 - val_CER: 0.0714 - val_WER: 0.1859 - lr: 4.5000e-04
Epoch 147/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.2624 - CER: 0.0841 - WER: 0.2296
Epoch 147: val_CER did not improve from 0.07009
5426/5426 [==============================] - 226s 42ms/step - loss: 1.2624 - CER: 0.0841 - WER: 0.2296 - val_loss: 1.1880 - val_CER: 0.0702 - val_WER: 0.1882 - lr: 4.0500e-04
Epoch 148/150
5425/5426 [============================>.] - ETA: 0s - loss: 1.2627 - CER: 0.0816 - WER: 0.2249
Epoch 148: val_CER did not improve from 0.07009
5426/5426 [==============================] - 232s 43ms/step - loss: 1.2626 - CER: 0.0816 - WER: 0.2249 - val_loss: 1.2213 - val_CER: 0.0719 - val_WER: 0.1912 - lr: 4.0500e-04
Epoch 149/150
5426/5426 [==============================] - ETA: 0s - loss: 1.2452 - CER: 0.0818 - WER: 0.2262
Epoch 149: val_CER did not improve from 0.07009
5426/5426 [==============================] - 225s 41ms/step - loss: 1.2452 - CER: 0.0818 - WER: 0.2262 - val_loss: 1.1879 - val_CER: 0.0702 - val_WER: 0.1868 - lr: 4.0500e-04
Epoch 150/150
5426/5426 [==============================] - ETA: 0s - loss: 1.2449 - CER: 0.0814 - WER: 0.2268
Epoch 150: val_CER improved from 0.07009 to 0.06946, saving model to Models/03_handwriting_recognition/202311290851/model.h5
5426/5426 [==============================] - 222s 41ms/step - loss: 1.2449 - CER: 0.0814 - WER: 0.2268 - val_loss: 1.1758 - val_CER: 0.0695 - val_WER: 0.1854 - lr: 4.0500e-04